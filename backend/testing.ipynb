{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gym Environment\n",
    "Example following Stable Baseline 3's documentation with a gym environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import gymnasium as gym\n",
    "from stable_baselines3 import A2C\n",
    "from stable_baselines3.common.vec_env import VecVideoRecorder, DummyVecEnv, VecMonitor\n",
    "from stable_baselines3.common.env_checker import check_env\n",
    "\n",
    "# Create the environment\n",
    "env = gym.make(\"CartPole-v1\", render_mode=\"rgb_array\")\n",
    "\n",
    "\n",
    "check_env(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 23.5     |\n",
      "|    ep_rew_mean        | 23.5     |\n",
      "| time/                 |          |\n",
      "|    fps                | 402      |\n",
      "|    iterations         | 100      |\n",
      "|    time_elapsed       | 1        |\n",
      "|    total_timesteps    | 500      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.674   |\n",
      "|    explained_variance | -0.983   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 99       |\n",
      "|    policy_loss        | -2.23    |\n",
      "|    value_loss         | 34.8     |\n",
      "------------------------------------\n",
      "Saving video to c:\\Users\\Michael\\Code\\stakeholder-mapping\\backend\\videos\\cartpole_a2c-step-0-to-step-1000.mp4\n",
      "Moviepy - Building video c:\\Users\\Michael\\Code\\stakeholder-mapping\\backend\\videos\\cartpole_a2c-step-0-to-step-1000.mp4.\n",
      "Moviepy - Writing video c:\\Users\\Michael\\Code\\stakeholder-mapping\\backend\\videos\\cartpole_a2c-step-0-to-step-1000.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready c:\\Users\\Michael\\Code\\stakeholder-mapping\\backend\\videos\\cartpole_a2c-step-0-to-step-1000.mp4\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 20.7     |\n",
      "|    ep_rew_mean        | 20.7     |\n",
      "| time/                 |          |\n",
      "|    fps                | 304      |\n",
      "|    iterations         | 200      |\n",
      "|    time_elapsed       | 3        |\n",
      "|    total_timesteps    | 1000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.649   |\n",
      "|    explained_variance | -0.159   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 199      |\n",
      "|    policy_loss        | -4.02    |\n",
      "|    value_loss         | 87.6     |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 19.9     |\n",
      "|    ep_rew_mean        | 19.9     |\n",
      "| time/                 |          |\n",
      "|    fps                | 419      |\n",
      "|    iterations         | 300      |\n",
      "|    time_elapsed       | 3        |\n",
      "|    total_timesteps    | 1500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.63    |\n",
      "|    explained_variance | -0.0703  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 299      |\n",
      "|    policy_loss        | -4.67    |\n",
      "|    value_loss         | 137      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 17.4     |\n",
      "|    ep_rew_mean        | 17.4     |\n",
      "| time/                 |          |\n",
      "|    fps                | 517      |\n",
      "|    iterations         | 400      |\n",
      "|    time_elapsed       | 3        |\n",
      "|    total_timesteps    | 2000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.663   |\n",
      "|    explained_variance | -0.0109  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 399      |\n",
      "|    policy_loss        | 1.27     |\n",
      "|    value_loss         | 7.22     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 15.6     |\n",
      "|    ep_rew_mean        | 15.6     |\n",
      "| time/                 |          |\n",
      "|    fps                | 601      |\n",
      "|    iterations         | 500      |\n",
      "|    time_elapsed       | 4        |\n",
      "|    total_timesteps    | 2500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.636   |\n",
      "|    explained_variance | 0.0289   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 499      |\n",
      "|    policy_loss        | 1.4      |\n",
      "|    value_loss         | 7.01     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 16       |\n",
      "|    ep_rew_mean        | 16       |\n",
      "| time/                 |          |\n",
      "|    fps                | 674      |\n",
      "|    iterations         | 600      |\n",
      "|    time_elapsed       | 4        |\n",
      "|    total_timesteps    | 3000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.593   |\n",
      "|    explained_variance | -0.0447  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 599      |\n",
      "|    policy_loss        | 1.41     |\n",
      "|    value_loss         | 6.57     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 17.5     |\n",
      "|    ep_rew_mean        | 17.5     |\n",
      "| time/                 |          |\n",
      "|    fps                | 737      |\n",
      "|    iterations         | 700      |\n",
      "|    time_elapsed       | 4        |\n",
      "|    total_timesteps    | 3500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.576   |\n",
      "|    explained_variance | -0.0427  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 699      |\n",
      "|    policy_loss        | 0.95     |\n",
      "|    value_loss         | 6.12     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 19.4     |\n",
      "|    ep_rew_mean        | 19.4     |\n",
      "| time/                 |          |\n",
      "|    fps                | 793      |\n",
      "|    iterations         | 800      |\n",
      "|    time_elapsed       | 5        |\n",
      "|    total_timesteps    | 4000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.558   |\n",
      "|    explained_variance | -0.0322  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 799      |\n",
      "|    policy_loss        | 0.925    |\n",
      "|    value_loss         | 5.65     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 21.5     |\n",
      "|    ep_rew_mean        | 21.5     |\n",
      "| time/                 |          |\n",
      "|    fps                | 845      |\n",
      "|    iterations         | 900      |\n",
      "|    time_elapsed       | 5        |\n",
      "|    total_timesteps    | 4500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.57    |\n",
      "|    explained_variance | 0.00714  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 899      |\n",
      "|    policy_loss        | 0.711    |\n",
      "|    value_loss         | 5.04     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 24.1      |\n",
      "|    ep_rew_mean        | 24.1      |\n",
      "| time/                 |           |\n",
      "|    fps                | 891       |\n",
      "|    iterations         | 1000      |\n",
      "|    time_elapsed       | 5         |\n",
      "|    total_timesteps    | 5000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.26     |\n",
      "|    explained_variance | -0.000818 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 999       |\n",
      "|    policy_loss        | -26.9     |\n",
      "|    value_loss         | 787       |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 27       |\n",
      "|    ep_rew_mean        | 27       |\n",
      "| time/                 |          |\n",
      "|    fps                | 931      |\n",
      "|    iterations         | 1100     |\n",
      "|    time_elapsed       | 5        |\n",
      "|    total_timesteps    | 5500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.382   |\n",
      "|    explained_variance | -0.00017 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1099     |\n",
      "|    policy_loss        | 0.857    |\n",
      "|    value_loss         | 4.18     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 30        |\n",
      "|    ep_rew_mean        | 30        |\n",
      "| time/                 |           |\n",
      "|    fps                | 967       |\n",
      "|    iterations         | 1200      |\n",
      "|    time_elapsed       | 6         |\n",
      "|    total_timesteps    | 6000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.45     |\n",
      "|    explained_variance | -3.76e-05 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1199      |\n",
      "|    policy_loss        | 0.565     |\n",
      "|    value_loss         | 3.68      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 34.9     |\n",
      "|    ep_rew_mean        | 34.8     |\n",
      "| time/                 |          |\n",
      "|    fps                | 999      |\n",
      "|    iterations         | 1300     |\n",
      "|    time_elapsed       | 6        |\n",
      "|    total_timesteps    | 6500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.519   |\n",
      "|    explained_variance | 0.000132 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1299     |\n",
      "|    policy_loss        | 0.547    |\n",
      "|    value_loss         | 3.17     |\n",
      "------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import gymnasium as gym\n",
    "from stable_baselines3 import A2C\n",
    "from stable_baselines3.common.vec_env import VecVideoRecorder, DummyVecEnv, VecMonitor\n",
    "\n",
    "# Create the environment\n",
    "env = gym.make(\"CartPole-v1\", render_mode=\"rgb_array\")\n",
    "\n",
    "# Wrap the environment to record video\n",
    "env = DummyVecEnv([lambda: env])\n",
    "env = VecMonitor(env)\n",
    "video_length = 1000  # Length of the video in steps\n",
    "\n",
    "# Create the video recorder (specify save path and video length)\n",
    "video_folder = 'videos/'\n",
    "env = VecVideoRecorder(env, video_folder=video_folder,\n",
    "                       record_video_trigger=lambda x: x == 0,  # record the first episode\n",
    "                       video_length=video_length, name_prefix=\"cartpole_a2c\")\n",
    "\n",
    "# Train the model\n",
    "model = A2C(\"MlpPolicy\", env, verbose=1)\n",
    "model.learn(total_timesteps=10_000)\n",
    "\n",
    "# Reset the environment\n",
    "obs = env.reset()\n",
    "for i in range(video_length):\n",
    "    action, _state = model.predict(obs, deterministic=True)\n",
    "    obs, reward, done, info = env.step(action)\n",
    "\n",
    "    # Render each frame (Optional if not viewing)\n",
    "    env.render(\"human\")\n",
    "\n",
    "# Close the environment and the video recorder\n",
    "env.close()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom environment\n",
    "Starting code for a snake game, to be converted into a custom gym environment\n",
    "\n",
    "Below cell implements game logic and rendering with opencv (wasd movement, q to quit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import random\n",
    "import time\n",
    "\n",
    "def collision_with_apple(apple_position, score):\n",
    "    apple_position = [random.randrange(1,50)*10,random.randrange(1,50)*10]\n",
    "    score += 1\n",
    "    return apple_position, score\n",
    "\n",
    "def collision_with_boundaries(snake_head):\n",
    "    if snake_head[0]>=500 or snake_head[0]<0 or snake_head[1]>=500 or snake_head[1]<0 :\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def collision_with_self(snake_position):\n",
    "    snake_head = snake_position[0]\n",
    "    if snake_head in snake_position[1:]:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "img = np.zeros((500,500,3),dtype='uint8')\n",
    "# Initial Snake and Apple position\n",
    "snake_position = [[250,250],[240,250],[230,250]]\n",
    "apple_position = [random.randrange(1,50)*10,random.randrange(1,50)*10]\n",
    "score = 0\n",
    "prev_button_direction = 1\n",
    "button_direction = 1\n",
    "snake_head = [250,250]\n",
    "while True:\n",
    "    cv2.imshow('a',img)\n",
    "    cv2.waitKey(1)\n",
    "    img = np.zeros((500,500,3),dtype='uint8')\n",
    "    # Display Apple\n",
    "    cv2.rectangle(img,(apple_position[0],apple_position[1]),(apple_position[0]+10,apple_position[1]+10),(0,0,255),3)\n",
    "    # Display Snake\n",
    "    for position in snake_position:\n",
    "        cv2.rectangle(img,(position[0],position[1]),(position[0]+10,position[1]+10),(0,255,0),3)\n",
    "    \n",
    "    # Takes step after fixed time\n",
    "    t_end = time.time() + 0.05\n",
    "    k = -1\n",
    "    while time.time() < t_end:\n",
    "        if k == -1:\n",
    "            k = cv2.waitKey(1)\n",
    "        else:\n",
    "            continue\n",
    "            \n",
    "    # 0-Left, 1-Right, 3-Up, 2-Down, q-Break\n",
    "    # a-Left, d-Right, w-Up, s-Down\n",
    "\n",
    "    if k == ord('a') and prev_button_direction != 1:\n",
    "        button_direction = 0\n",
    "    elif k == ord('d') and prev_button_direction != 0:\n",
    "        button_direction = 1\n",
    "    elif k == ord('w') and prev_button_direction != 2:\n",
    "        button_direction = 3\n",
    "    elif k == ord('s') and prev_button_direction != 3:\n",
    "        button_direction = 2\n",
    "    elif k == ord('q'):\n",
    "        break\n",
    "    else:\n",
    "        button_direction = button_direction\n",
    "    prev_button_direction = button_direction\n",
    "\n",
    "    # Change the head position based on the button direction\n",
    "    if button_direction == 1:\n",
    "        snake_head[0] += 10\n",
    "    elif button_direction == 0:\n",
    "        snake_head[0] -= 10\n",
    "    elif button_direction == 2:\n",
    "        snake_head[1] += 10\n",
    "    elif button_direction == 3:\n",
    "        snake_head[1] -= 10\n",
    "\n",
    "    # Increase Snake length on eating apple\n",
    "    if snake_head == apple_position:\n",
    "        apple_position, score = collision_with_apple(apple_position, score)\n",
    "        snake_position.insert(0,list(snake_head))\n",
    "\n",
    "    else:\n",
    "        snake_position.insert(0,list(snake_head))\n",
    "        snake_position.pop()\n",
    "        \n",
    "    # On collision kill the snake and print the score\n",
    "    if collision_with_boundaries(snake_head) == 1 or collision_with_self(snake_position) == 1:\n",
    "        font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "        img = np.zeros((500,500,3),dtype='uint8')\n",
    "        cv2.putText(img,'Your Score is {}'.format(score),(140,250), font, 1,(255,255,255),2,cv2.LINE_AA)\n",
    "        cv2.imshow('a',img)\n",
    "        cv2.waitKey(0)\n",
    "        break\n",
    "        \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "from gymnasium import spaces\n",
    "import numpy as np\n",
    "import cv2\n",
    "import random\n",
    "import time\n",
    "from collections import deque\n",
    "\n",
    "SNAKE_LEN_GOAL = 30\n",
    "\n",
    "def collision_with_apple(apple_position, score):\n",
    "    apple_position = [random.randrange(1,50)*10,random.randrange(1,50)*10]\n",
    "    score += 1\n",
    "    return apple_position, score\n",
    "\n",
    "def collision_with_boundaries(snake_head):\n",
    "    if snake_head[0]>=500 or snake_head[0]<0 or snake_head[1]>=500 or snake_head[1]<0 :\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def collision_with_self(snake_position):\n",
    "    snake_head = snake_position[0]\n",
    "    if snake_head in snake_position[1:]:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "\n",
    "class SnekEnv(gym.Env):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(SnekEnv, self).__init__()\n",
    "        # Define action and observation space\n",
    "        # They must be gym.spaces objects\n",
    "        # Example when using discrete actions:\n",
    "        self.action_space = spaces.Discrete(4)\n",
    "        # Example for using image as input (channel-first; channel-last also works):\n",
    "        self.observation_space = spaces.Box(low=-500, high=500,\n",
    "                                            shape=(5+SNAKE_LEN_GOAL,), dtype=np.float32)\n",
    "\n",
    "    def step(self, action):\n",
    "        self.prev_actions.append(action)\n",
    "        cv2.imshow('a',self.img)\n",
    "        cv2.waitKey(1)\n",
    "        self.img = np.zeros((500,500,3),dtype='uint8')\n",
    "        # Display Apple\n",
    "        cv2.rectangle(self.img,(self.apple_position[0],self.apple_position[1]),(self.apple_position[0]+10,self.apple_position[1]+10),(0,0,255),3)\n",
    "        # Display Snake\n",
    "        for position in self.snake_position:\n",
    "            cv2.rectangle(self.img,(position[0],position[1]),(position[0]+10,position[1]+10),(0,255,0),3)\n",
    "        \n",
    "        # Takes step after fixed time\n",
    "        t_end = time.time() + 0.05\n",
    "        k = -1\n",
    "        while time.time() < t_end:\n",
    "            if k == -1:\n",
    "                k = cv2.waitKey(1)\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "        button_direction = action\n",
    "        # Change the head position based on the button direction\n",
    "        if button_direction == 1:\n",
    "            self.snake_head[0] += 10\n",
    "        elif button_direction == 0:\n",
    "            self.snake_head[0] -= 10\n",
    "        elif button_direction == 2:\n",
    "            self.snake_head[1] += 10\n",
    "        elif button_direction == 3:\n",
    "            self.snake_head[1] -= 10\n",
    "\n",
    "\n",
    "        apple_reward = 0\n",
    "        # Increase Snake length on eating apple\n",
    "        if self.snake_head == self.apple_position:\n",
    "            self.apple_position, self.score = collision_with_apple(self.apple_position, self.score)\n",
    "            self.snake_position.insert(0,list(self.snake_head))\n",
    "            apple_reward = 10000\n",
    "\n",
    "        else:\n",
    "            self.snake_position.insert(0,list(self.snake_head))\n",
    "            self.snake_position.pop()\n",
    "        \n",
    "        # On collision kill the snake and print the score\n",
    "        if collision_with_boundaries(self.snake_head) == 1 or collision_with_self(self.snake_position) == 1:\n",
    "            font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "            self.img = np.zeros((500,500,3),dtype='uint8')\n",
    "            cv2.putText(self.img,'Your Score is {}'.format(self.score),(140,250), font, 1,(255,255,255),2,cv2.LINE_AA)\n",
    "            cv2.imshow('a',self.img)\n",
    "            self.done = True\n",
    "        \n",
    "\n",
    "\n",
    "        euclidean_dist_to_apple = np.linalg.norm(np.array(self.snake_head) - np.array(self.apple_position))\n",
    "\n",
    "        self.total_reward = ((250 - euclidean_dist_to_apple) + apple_reward)/100\n",
    "\n",
    "        self.reward = self.total_reward - self.prev_reward\n",
    "        self.prev_reward = self.total_reward\n",
    "\n",
    "        if self.done:\n",
    "            self.reward = -10\n",
    "        info = {}\n",
    "\n",
    "\n",
    "        head_x = self.snake_head[0]\n",
    "        head_y = self.snake_head[1]\n",
    "\n",
    "        snake_length = len(self.snake_position)\n",
    "        apple_delta_x = self.apple_position[0] - head_x\n",
    "        apple_delta_y = self.apple_position[1] - head_y\n",
    "\n",
    "        # create observation:\n",
    "\n",
    "        observation = [head_x, head_y, apple_delta_x, apple_delta_y, snake_length] + list(self.prev_actions)\n",
    "        observation = np.array(observation, dtype=np.float32)\n",
    "\n",
    "        return observation, self.total_reward, self.done, False, info\n",
    "\n",
    "    def reset(self, seed=0):\n",
    "        random.seed(seed)\n",
    "        np.random.seed(seed)\n",
    "\n",
    "        self.img = np.zeros((500,500,3),dtype='uint8')\n",
    "        # Initial Snake and Apple position\n",
    "        self.snake_position = [[250,250],[240,250],[230,250]]\n",
    "        self.apple_position = [random.randrange(1,50)*10,random.randrange(1,50)*10]\n",
    "        self.score = 0\n",
    "        self.prev_button_direction = 1\n",
    "        self.button_direction = 1\n",
    "        self.snake_head = [250,250]\n",
    "\n",
    "        self.prev_reward = 0\n",
    "\n",
    "        self.done = False\n",
    "\n",
    "        head_x = self.snake_head[0]\n",
    "        head_y = self.snake_head[1]\n",
    "\n",
    "        snake_length = len(self.snake_position)\n",
    "        apple_delta_x = self.apple_position[0] - head_x\n",
    "        apple_delta_y = self.apple_position[1] - head_y\n",
    "\n",
    "        self.prev_actions = deque(maxlen = SNAKE_LEN_GOAL)  # however long we aspire the snake to be\n",
    "        for i in range(SNAKE_LEN_GOAL):\n",
    "            self.prev_actions.append(-1) # to create history\n",
    "\n",
    "        # create observation:\n",
    "        observation = [head_x, head_y, apple_delta_x, apple_delta_y, snake_length] + list(self.prev_actions)\n",
    "        observation = np.array(observation, dtype=np.float32)\n",
    "\n",
    "        return observation, {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3.common.env_checker import check_env\n",
    "\n",
    "env = SnekEnv()\n",
    "check_env(env)\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Logging to ./out\\run_1_0\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from stable_baselines3 import PPO\n",
    "out_dir = \"./out\"\n",
    "\n",
    "env = SnekEnv()\n",
    "env.reset()\n",
    "\n",
    "model = PPO(\"MlpPolicy\", env, verbose=1, tensorboard_log=out_dir)\n",
    "\n",
    "TIMESTEPS = 10000\n",
    "for i in range(1, 5):\n",
    "    model.learn(total_timesteps=TIMESTEPS, reset_num_timesteps=False, tb_log_name=f\"run_{i}\")\n",
    "    model.save(out_dir + f\"/model_{i}\")\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
