{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "from typing import Tuple\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import gymnasium\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from tianshou.data import Batch, Collector, VectorReplayBuffer\n",
    "from tianshou.env import DummyVectorEnv\n",
    "from tianshou.env.pettingzoo_env import PettingZooEnv\n",
    "from tianshou.policy import BasePolicy, DQNPolicy, MultiAgentPolicyManager\n",
    "from tianshou.trainer import offpolicy_trainer\n",
    "from tianshou.utils import TensorboardLogger\n",
    "from tianshou.utils.net.common import Net\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from env.negotiation import NegotiationEnv\n",
    "from env.negotiation import Outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_parser() -> argparse.ArgumentParser:\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--seed\", type=int, default=1626)\n",
    "    parser.add_argument(\"--eps-test\", type=float, default=0.05)\n",
    "    parser.add_argument(\"--eps-train\", type=float, default=0.1)\n",
    "    parser.add_argument(\"--buffer-size\", type=int, default=20000)\n",
    "    parser.add_argument(\"--lr\", type=float, default=1e-4)\n",
    "    parser.add_argument(\n",
    "        \"--gamma\", type=float, default=0.9, help=\"a smaller gamma favors earlier win\"\n",
    "    )\n",
    "    parser.add_argument(\"--n-step\", type=int, default=3)\n",
    "    parser.add_argument(\"--target-update-freq\", type=int, default=320)\n",
    "    parser.add_argument(\"--epoch\", type=int, default=20)\n",
    "    parser.add_argument(\"--step-per-epoch\", type=int, default=1000)\n",
    "    parser.add_argument(\"--step-per-collect\", type=int, default=10)\n",
    "    parser.add_argument(\"--update-per-step\", type=float, default=0.1)\n",
    "    parser.add_argument(\"--batch-size\", type=int, default=64)\n",
    "    parser.add_argument(\n",
    "        \"--hidden-sizes\", type=int, nargs=\"*\", default=[128, 128, 128, 128]\n",
    "    )\n",
    "    parser.add_argument(\"--training-num\", type=int, default=10)\n",
    "    parser.add_argument(\"--test-num\", type=int, default=10)\n",
    "    parser.add_argument(\"--logdir\", type=str, default=\"log\")\n",
    "    parser.add_argument(\"--render\", type=float, default=0.1)\n",
    "    parser.add_argument(\n",
    "        \"--win-rate\",\n",
    "        type=float,\n",
    "        default=0.6,\n",
    "        help=\"the expected winning rate: Optimal policy can get 0.7\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--watch\",\n",
    "        default=False,\n",
    "        action=\"store_true\",\n",
    "        help=\"no training, \" \"watch the play of pre-trained models\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--agent-id\",\n",
    "        type=int,\n",
    "        default=2,\n",
    "        help=\"the learned agent plays as the\"\n",
    "        \" agent_id-th player. Choices are 1 and 2.\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--resume-path\",\n",
    "        type=str,\n",
    "        default=\"\",\n",
    "        help=\"the path of agent pth file \" \"for resuming from a pre-trained agent\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--opponent-path\",\n",
    "        type=str,\n",
    "        default=\"\",\n",
    "        help=\"the path of opponent agent pth file \"\n",
    "        \"for resuming from a pre-trained agent\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--device\", type=str, default=\"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    )\n",
    "    return parser\n",
    "\n",
    "\n",
    "def get_args() -> argparse.Namespace:\n",
    "    parser = get_parser()\n",
    "    return parser.parse_known_args()[0]\n",
    "\n",
    "\n",
    "def get_agents(\n",
    "    args: argparse.Namespace = get_args(),\n",
    "    stakeholder_vals: np.ndarray | None = None\n",
    ") -> Tuple[BasePolicy, torch.optim.Optimizer, list]:\n",
    "    env = get_env(stakeholder_vals)\n",
    "    observation_space = (\n",
    "        env.observation_space[\"observation\"]\n",
    "        if isinstance(env.observation_space, gymnasium.spaces.Dict)\n",
    "        else env.observation_space\n",
    "    )\n",
    "    args.state_shape = observation_space.shape or observation_space.n\n",
    "    args.action_shape = env.action_space.shape or env.action_space.n\n",
    "\n",
    "\n",
    "    agents = []\n",
    "    for _ in range(env.env.n_agents):\n",
    "        net = Net(\n",
    "            args.state_shape,\n",
    "            args.action_shape,\n",
    "            hidden_sizes=args.hidden_sizes,\n",
    "            device=args.device,\n",
    "        ).to(args.device)\n",
    "        optim = torch.optim.Adam(net.parameters(), lr=args.lr)\n",
    "\n",
    "        agents.append(DQNPolicy(net, optim, args.gamma, args.n_step, target_update_freq=args.target_update_freq))\n",
    "    policy = MultiAgentPolicyManager(agents, env)\n",
    "    return policy, env.agents\n",
    "\n",
    "\n",
    "def get_env(data=None, render_mode=None, weights=None):\n",
    "    return PettingZooEnv(NegotiationEnv(stakeholder_matrix=data, render_mode=render_mode, weights=weights))\n",
    "\n",
    "\n",
    "def train_agent(\n",
    "    args: argparse.Namespace = get_args(),\n",
    "    stakeholder_vals: np.ndarray | None = None,\n",
    "    weights = None\n",
    ") -> Tuple[dict, BasePolicy]:\n",
    "    # ======== environment setup =========\n",
    "    train_envs = DummyVectorEnv([lambda: get_env(stakeholder_vals, weights=weights) for _ in range(args.training_num)])\n",
    "    test_envs = DummyVectorEnv([lambda: get_env(stakeholder_vals, weights=weights) for _ in range(args.test_num)])\n",
    "    # seed\n",
    "    np.random.seed(args.seed)\n",
    "    torch.manual_seed(args.seed)\n",
    "    train_envs.seed(args.seed)\n",
    "    test_envs.seed(args.seed)\n",
    "\n",
    "    # ======== agent setup =========\n",
    "    policy, agents = get_agents(args, stakeholder_vals)\n",
    "\n",
    "    # ======== collector setup =========\n",
    "    train_collector = Collector(\n",
    "        policy,\n",
    "        train_envs,\n",
    "        VectorReplayBuffer(args.buffer_size, len(train_envs)),\n",
    "        exploration_noise=True,\n",
    "    )\n",
    "    test_collector = Collector(policy, test_envs, exploration_noise=True)\n",
    "    # policy.set_eps(1)\n",
    "    train_collector.collect(n_step=args.batch_size * args.training_num)\n",
    "\n",
    "    # ======== tensorboard logging setup =========\n",
    "    log_path = os.path.join(args.logdir, \"negotiate\", \"dqn\")\n",
    "    writer = SummaryWriter(log_path)\n",
    "    writer.add_text(\"args\", str(args))\n",
    "    logger = TensorboardLogger(writer)\n",
    "\n",
    "    # ======== callback functions used during training =========\n",
    "    def save_best_fn(policy):\n",
    "        if hasattr(args, \"model_save_path\"):\n",
    "            model_save_path = args.model_save_path\n",
    "        else:\n",
    "            model_save_path = os.path.join(\n",
    "                args.logdir, \"negotiate\", \"dqn\", \"policy.pth\"\n",
    "            )\n",
    "        torch.save(\n",
    "            policy.policies[agents[args.agent_id - 1]].state_dict(), model_save_path\n",
    "        )\n",
    "\n",
    "    def stop_fn(mean_rewards):\n",
    "        return mean_rewards >= args.win_rate\n",
    "\n",
    "    def train_fn(epoch, env_step):\n",
    "        policy.policies[agents[args.agent_id - 1]].set_eps(args.eps_train)\n",
    "\n",
    "    def test_fn(epoch, env_step):\n",
    "        policy.policies[agents[args.agent_id - 1]].set_eps(args.eps_test)\n",
    "\n",
    "    def reward_metric(rews):\n",
    "        return rews[:, args.agent_id - 1]\n",
    "\n",
    "    # trainer\n",
    "    result = offpolicy_trainer(\n",
    "        policy,\n",
    "        train_collector,\n",
    "        test_collector,\n",
    "        args.epoch,\n",
    "        args.step_per_epoch,\n",
    "        args.step_per_collect,\n",
    "        args.test_num,\n",
    "        args.batch_size,\n",
    "        train_fn=train_fn,\n",
    "        test_fn=test_fn,\n",
    "        # stop_fn=stop_fn,\n",
    "        save_best_fn=save_best_fn,\n",
    "        update_per_step=args.update_per_step,\n",
    "        logger=logger,\n",
    "        test_in_train=False,\n",
    "        reward_metric=reward_metric\n",
    "    )\n",
    "\n",
    "    return result, policy.policies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/katherinehunter/Github/stakeholder-mapping/backend/env/negotiation.py:77: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  self.standardisation_factor = (2 * self.w_power + self.w_urgency\n",
      "Epoch #1: 1001it [00:00, 1257.54it/s, agent_1/loss=316.311, agent_2/loss=331.510, agent_3/loss=520.093, agent_4/loss=268.047, agent_5/loss=0.032, env_step=1000, len=0, n/ep=0, n/st=10, rew=0.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #1: test_reward: -544.300000 ± 348.137523, best_reward: -544.300000 ± 348.137523 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #2: 1001it [00:00, 1854.56it/s, agent_1/loss=345.018, agent_2/loss=529.218, agent_3/loss=445.684, agent_4/loss=241.586, agent_5/loss=0.001, env_step=2000, len=0, n/ep=0, n/st=10, rew=0.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #2: test_reward: -434.175000 ± 430.563149, best_reward: -434.175000 ± 430.563149 in #2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #3: 1001it [00:00, 1866.98it/s, agent_1/loss=489.083, agent_2/loss=494.020, agent_3/loss=536.780, agent_4/loss=309.501, agent_5/loss=0.000, env_step=3000, len=0, n/ep=0, n/st=10, rew=0.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #3: test_reward: -578.625000 ± 336.792652, best_reward: -434.175000 ± 430.563149 in #2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #4: 1001it [00:00, 1868.73it/s, agent_1/loss=524.929, agent_2/loss=355.524, agent_3/loss=389.463, agent_4/loss=243.529, agent_5/loss=0.003, env_step=4000, len=0, n/ep=0, n/st=10, rew=0.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #4: test_reward: -793.075000 ± 370.276688, best_reward: -434.175000 ± 430.563149 in #2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #5: 1001it [00:00, 1698.76it/s, agent_1/loss=613.072, agent_2/loss=505.277, agent_3/loss=302.510, agent_4/loss=271.676, agent_5/loss=0.000, env_step=5000, len=501, n/ep=0, n/st=10, rew=-172.23]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #5: test_reward: -709.925000 ± 279.557240, best_reward: -434.175000 ± 430.563149 in #2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #6: 1001it [00:00, 1853.54it/s, agent_1/loss=518.867, agent_2/loss=311.405, agent_3/loss=180.470, agent_4/loss=213.500, agent_5/loss=0.000, env_step=6000, len=501, n/ep=0, n/st=10, rew=-172.23]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #6: test_reward: -602.275000 ± 344.198098, best_reward: -434.175000 ± 430.563149 in #2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #7: 1001it [00:00, 1840.55it/s, agent_1/loss=458.928, agent_2/loss=620.320, agent_3/loss=137.369, agent_4/loss=297.923, agent_5/loss=0.002, env_step=7000, len=501, n/ep=0, n/st=10, rew=-172.23]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #7: test_reward: -387.275000 ± 436.074627, best_reward: -387.275000 ± 436.074627 in #7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #8: 1001it [00:00, 1856.06it/s, agent_1/loss=380.500, agent_2/loss=401.172, agent_3/loss=255.404, agent_4/loss=263.700, agent_5/loss=0.001, env_step=8000, len=501, n/ep=0, n/st=10, rew=-172.23]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #8: test_reward: 107.525000 ± 199.647860, best_reward: 107.525000 ± 199.647860 in #8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #9: 1001it [00:00, 1828.15it/s, agent_1/loss=519.162, agent_2/loss=479.380, agent_3/loss=251.408, agent_4/loss=264.600, agent_5/loss=0.000, env_step=9000, len=451, n/ep=0, n/st=10, rew=189.75]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #9: test_reward: 120.075000 ± 232.617713, best_reward: 120.075000 ± 232.617713 in #9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #10: 1001it [00:00, 1802.86it/s, agent_1/loss=498.248, agent_2/loss=335.957, agent_3/loss=269.898, agent_4/loss=210.010, agent_5/loss=0.002, env_step=10000, len=151, n/ep=0, n/st=10, rew=404.50]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #10: test_reward: 195.075000 ± 270.185771, best_reward: 195.075000 ± 270.185771 in #10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #11: 1001it [00:00, 1803.58it/s, agent_1/loss=566.911, agent_2/loss=284.346, agent_3/loss=210.711, agent_4/loss=267.557, agent_5/loss=0.002, env_step=11000, len=153, n/ep=0, n/st=10, rew=170.38]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #11: test_reward: 125.725000 ± 171.310042, best_reward: 195.075000 ± 270.185771 in #10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #12: 1001it [00:00, 1807.19it/s, agent_1/loss=504.537, agent_2/loss=535.079, agent_3/loss=235.305, agent_4/loss=324.589, agent_5/loss=0.001, env_step=12000, len=281, n/ep=0, n/st=10, rew=-40.25]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #12: test_reward: 7.600000 ± 252.624009, best_reward: 195.075000 ± 270.185771 in #10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #13: 1001it [00:00, 1735.16it/s, agent_1/loss=537.541, agent_2/loss=480.166, agent_3/loss=344.168, agent_4/loss=293.094, agent_5/loss=0.002, env_step=13000, len=331, n/ep=0, n/st=10, rew=206.50]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #13: test_reward: -32.675000 ± 419.227698, best_reward: 195.075000 ± 270.185771 in #10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #14: 1001it [00:00, 1715.45it/s, agent_1/loss=641.059, agent_2/loss=412.640, agent_3/loss=223.195, agent_4/loss=295.797, agent_5/loss=0.003, env_step=14000, len=481, n/ep=0, n/st=10, rew=84.25]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #14: test_reward: 16.350000 ± 357.794777, best_reward: 195.075000 ± 270.185771 in #10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #15: 1001it [00:00, 1795.22it/s, agent_1/loss=671.220, agent_2/loss=540.938, agent_3/loss=351.545, agent_4/loss=331.137, agent_5/loss=0.005, env_step=15000, len=206, n/ep=0, n/st=10, rew=374.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #15: test_reward: -87.700000 ± 374.370869, best_reward: 195.075000 ± 270.185771 in #10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #16: 1001it [00:00, 1525.25it/s, agent_1/loss=755.431, agent_2/loss=487.450, agent_3/loss=404.457, agent_4/loss=311.339, agent_5/loss=0.005, env_step=16000, len=331, n/ep=2, n/st=10, rew=26.37]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #16: test_reward: -10.700000 ± 383.082576, best_reward: 195.075000 ± 270.185771 in #10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #17: 1001it [00:00, 1679.31it/s, agent_1/loss=558.571, agent_2/loss=344.600, agent_3/loss=414.061, agent_4/loss=302.372, agent_5/loss=0.004, env_step=17000, len=181, n/ep=0, n/st=10, rew=-32.50]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #17: test_reward: 169.700000 ± 293.753506, best_reward: 195.075000 ± 270.185771 in #10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #18: 1001it [00:00, 1726.14it/s, agent_1/loss=563.558, agent_2/loss=424.796, agent_3/loss=229.502, agent_4/loss=379.999, agent_5/loss=0.003, env_step=18000, len=281, n/ep=0, n/st=10, rew=348.50]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #18: test_reward: 135.200000 ± 265.665104, best_reward: 195.075000 ± 270.185771 in #10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #19: 1001it [00:00, 1696.94it/s, agent_1/loss=621.038, agent_2/loss=529.397, agent_3/loss=225.358, agent_4/loss=357.795, agent_5/loss=0.003, env_step=19000, len=501, n/ep=1, n/st=10, rew=-136.75]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #19: test_reward: 325.150000 ± 207.786405, best_reward: 325.150000 ± 207.786405 in #19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #20: 1001it [00:00, 1723.59it/s, agent_1/loss=512.683, agent_2/loss=455.059, agent_3/loss=162.176, agent_4/loss=282.564, agent_5/loss=0.006, env_step=20000, len=121, n/ep=0, n/st=10, rew=540.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #20: test_reward: 248.475000 ± 209.712465, best_reward: 325.150000 ± 207.786405 in #19\n",
      "Final state:\n",
      "[[1 1 1 1 1]\n",
      " [1 1 1 1 0]\n",
      " [1 1 1 1 0]\n",
      " [1 1 1 1 1]\n",
      " [1 0 0 1 1]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #1: 1001it [00:00, 1859.76it/s, agent_1/loss=429.917, agent_2/loss=370.354, agent_3/loss=377.775, agent_4/loss=444.516, agent_5/loss=0.033, env_step=1000, len=0, n/ep=0, n/st=10, rew=0.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #1: test_reward: -1037.700000 ± 194.455837, best_reward: -926.850000 ± 269.168864 in #0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #2: 1001it [00:00, 1824.28it/s, agent_1/loss=735.168, agent_2/loss=759.588, agent_3/loss=432.783, agent_4/loss=442.891, agent_5/loss=0.001, env_step=2000, len=0, n/ep=0, n/st=10, rew=0.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #2: test_reward: -646.425000 ± 259.683920, best_reward: -646.425000 ± 259.683920 in #2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #3: 1001it [00:00, 1893.30it/s, agent_1/loss=803.989, agent_2/loss=575.419, agent_3/loss=529.620, agent_4/loss=412.545, agent_5/loss=0.000, env_step=3000, len=0, n/ep=0, n/st=10, rew=0.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #3: test_reward: -772.625000 ± 202.166060, best_reward: -646.425000 ± 259.683920 in #2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #4: 1001it [00:00, 1796.47it/s, agent_1/loss=538.873, agent_2/loss=510.280, agent_3/loss=247.385, agent_4/loss=273.456, agent_5/loss=0.003, env_step=4000, len=451, n/ep=0, n/st=10, rew=-306.75]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #4: test_reward: 37.675000 ± 301.475104, best_reward: 37.675000 ± 301.475104 in #4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #5: 1001it [00:00, 1785.95it/s, agent_1/loss=269.003, agent_2/loss=628.225, agent_3/loss=140.074, agent_4/loss=317.255, agent_5/loss=0.001, env_step=5000, len=106, n/ep=0, n/st=10, rew=-10.50]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #5: test_reward: 80.950000 ± 107.029832, best_reward: 80.950000 ± 107.029832 in #5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #6: 1001it [00:00, 1548.11it/s, agent_1/loss=589.982, agent_2/loss=581.908, agent_3/loss=197.506, agent_4/loss=350.855, agent_5/loss=0.001, env_step=6000, len=26, n/ep=0, n/st=10, rew=-2.50]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #6: test_reward: 221.925000 ± 156.207876, best_reward: 221.925000 ± 156.207876 in #6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #7: 1001it [00:00, 1702.77it/s, agent_1/loss=605.663, agent_2/loss=410.665, agent_3/loss=236.932, agent_4/loss=274.096, agent_5/loss=0.003, env_step=7000, len=46, n/ep=0, n/st=10, rew=-4.50]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #7: test_reward: 197.425000 ± 101.110586, best_reward: 221.925000 ± 156.207876 in #6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #8: 1001it [00:00, 1452.27it/s, agent_1/loss=604.788, agent_2/loss=537.123, agent_3/loss=192.244, agent_4/loss=278.363, agent_5/loss=0.004, env_step=8000, len=281, n/ep=0, n/st=10, rew=-90.75]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #8: test_reward: 204.150000 ± 141.347276, best_reward: 221.925000 ± 156.207876 in #6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #9: 1001it [00:01, 949.68it/s, agent_1/loss=522.736, agent_2/loss=543.982, agent_3/loss=317.074, agent_4/loss=340.603, agent_5/loss=0.005, env_step=9000, len=111, n/ep=0, n/st=10, rew=378.50]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #9: test_reward: 197.150000 ± 139.922800, best_reward: 221.925000 ± 156.207876 in #6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #10: 1001it [00:00, 1461.70it/s, agent_1/loss=345.110, agent_2/loss=581.797, agent_3/loss=306.236, agent_4/loss=412.344, agent_5/loss=0.006, env_step=10000, len=91, n/ep=0, n/st=10, rew=177.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #10: test_reward: 204.350000 ± 170.613020, best_reward: 221.925000 ± 156.207876 in #6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #11: 1001it [00:00, 1660.76it/s, agent_1/loss=522.963, agent_2/loss=783.804, agent_3/loss=258.057, agent_4/loss=205.833, agent_5/loss=0.008, env_step=11000, len=121, n/ep=0, n/st=10, rew=266.50]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #11: test_reward: 226.000000 ± 148.306440, best_reward: 226.000000 ± 148.306440 in #11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #12: 1001it [00:00, 1674.82it/s, agent_1/loss=444.870, agent_2/loss=745.265, agent_3/loss=360.332, agent_4/loss=418.202, agent_5/loss=0.008, env_step=12000, len=193, n/ep=2, n/st=10, rew=570.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #12: test_reward: 319.050000 ± 206.491459, best_reward: 319.050000 ± 206.491459 in #12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #13: 1001it [00:00, 1505.85it/s, agent_1/loss=425.071, agent_2/loss=728.558, agent_3/loss=387.334, agent_4/loss=365.758, agent_5/loss=0.009, env_step=13000, len=136, n/ep=0, n/st=10, rew=475.25]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #13: test_reward: 134.150000 ± 153.373286, best_reward: 319.050000 ± 206.491459 in #12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #14: 1001it [00:01, 986.64it/s, agent_1/loss=442.609, agent_2/loss=906.736, agent_3/loss=311.090, agent_4/loss=539.489, agent_5/loss=0.008, env_step=14000, len=331, n/ep=0, n/st=10, rew=122.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #14: test_reward: 263.475000 ± 195.270436, best_reward: 319.050000 ± 206.491459 in #12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #15: 1001it [00:00, 1397.53it/s, agent_1/loss=708.723, agent_2/loss=784.862, agent_3/loss=341.064, agent_4/loss=305.471, agent_5/loss=0.011, env_step=15000, len=71, n/ep=0, n/st=10, rew=356.75]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #15: test_reward: 269.575000 ± 180.948924, best_reward: 319.050000 ± 206.491459 in #12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #16: 1001it [00:00, 1351.78it/s, agent_1/loss=500.872, agent_2/loss=759.758, agent_3/loss=290.065, agent_4/loss=373.547, agent_5/loss=0.009, env_step=16000, len=131, n/ep=0, n/st=10, rew=352.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #16: test_reward: 333.450000 ± 208.013635, best_reward: 333.450000 ± 208.013635 in #16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #17: 1001it [00:00, 1445.33it/s, agent_1/loss=618.338, agent_2/loss=729.190, agent_3/loss=376.354, agent_4/loss=407.035, agent_5/loss=0.011, env_step=17000, len=196, n/ep=0, n/st=10, rew=-19.50]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #17: test_reward: 263.875000 ± 257.278236, best_reward: 333.450000 ± 208.013635 in #16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #18: 1001it [00:00, 1454.88it/s, agent_1/loss=509.473, agent_2/loss=770.118, agent_3/loss=363.348, agent_4/loss=491.286, agent_5/loss=0.009, env_step=18000, len=161, n/ep=0, n/st=10, rew=439.25]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #18: test_reward: 185.350000 ± 222.971192, best_reward: 333.450000 ± 208.013635 in #16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #19: 1001it [00:00, 1663.27it/s, agent_1/loss=717.730, agent_2/loss=619.911, agent_3/loss=412.672, agent_4/loss=560.876, agent_5/loss=0.010, env_step=19000, len=131, n/ep=0, n/st=10, rew=366.25]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #19: test_reward: 333.450000 ± 208.013635, best_reward: 333.450000 ± 208.013635 in #16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #20: 1001it [00:00, 1409.29it/s, agent_1/loss=643.906, agent_2/loss=561.348, agent_3/loss=371.254, agent_4/loss=478.611, agent_5/loss=0.014, env_step=20000, len=103, n/ep=2, n/st=10, rew=210.75]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #20: test_reward: 464.875000 ± 242.293578, best_reward: 464.875000 ± 242.293578 in #20\n",
      "Final state:\n",
      "[[1 1 0 1 1]\n",
      " [1 1 1 1 1]\n",
      " [0 1 1 1 1]\n",
      " [1 1 1 1 1]\n",
      " [1 1 1 1 1]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #1: 1001it [00:00, 1472.16it/s, agent_1/loss=772.767, agent_2/loss=705.664, agent_3/loss=633.760, agent_4/loss=457.081, agent_5/loss=0.029, env_step=1000, len=0, n/ep=0, n/st=10, rew=0.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #1: test_reward: -916.400000 ± 267.241796, best_reward: -916.400000 ± 267.241796 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #2: 1001it [00:00, 1849.09it/s, agent_1/loss=959.278, agent_2/loss=758.813, agent_3/loss=602.212, agent_4/loss=576.430, agent_5/loss=0.001, env_step=2000, len=0, n/ep=0, n/st=10, rew=0.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #2: test_reward: -1010.525000 ± 128.329773, best_reward: -916.400000 ± 267.241796 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #3: 1001it [00:00, 1879.71it/s, agent_1/loss=641.017, agent_2/loss=704.948, agent_3/loss=402.569, agent_4/loss=478.002, agent_5/loss=0.000, env_step=3000, len=0, n/ep=0, n/st=10, rew=0.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #3: test_reward: -363.350000 ± 659.923056, best_reward: -363.350000 ± 659.923056 in #3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #4: 1001it [00:00, 1514.98it/s, agent_1/loss=372.186, agent_2/loss=1023.238, agent_3/loss=412.634, agent_4/loss=324.484, agent_5/loss=0.005, env_step=4000, len=61, n/ep=0, n/st=10, rew=-6.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #4: test_reward: 61.950000 ± 51.273507, best_reward: 61.950000 ± 51.273507 in #4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #5: 1001it [00:00, 1269.01it/s, agent_1/loss=497.667, agent_2/loss=935.678, agent_3/loss=420.741, agent_4/loss=466.838, agent_5/loss=0.004, env_step=5000, len=6, n/ep=0, n/st=10, rew=-0.50]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #5: test_reward: 97.800000 ± 81.034931, best_reward: 97.800000 ± 81.034931 in #5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #6: 1001it [00:00, 1508.45it/s, agent_1/loss=479.903, agent_2/loss=1052.359, agent_3/loss=739.843, agent_4/loss=471.572, agent_5/loss=0.002, env_step=6000, len=16, n/ep=1, n/st=10, rew=195.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #6: test_reward: 97.800000 ± 81.034931, best_reward: 97.800000 ± 81.034931 in #5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #7: 1001it [00:00, 1459.92it/s, agent_1/loss=412.894, agent_2/loss=1253.312, agent_3/loss=740.805, agent_4/loss=741.738, agent_5/loss=0.007, env_step=7000, len=31, n/ep=1, n/st=10, rew=220.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #7: test_reward: 97.800000 ± 81.034931, best_reward: 97.800000 ± 81.034931 in #5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #8: 1001it [00:00, 1660.84it/s, agent_1/loss=366.524, agent_2/loss=934.649, agent_3/loss=458.326, agent_4/loss=668.932, agent_5/loss=0.008, env_step=8000, len=11, n/ep=0, n/st=10, rew=-1.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #8: test_reward: 147.325000 ± 111.450889, best_reward: 147.325000 ± 111.450889 in #8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #9: 1001it [00:00, 1690.76it/s, agent_1/loss=397.571, agent_2/loss=958.231, agent_3/loss=525.534, agent_4/loss=525.273, agent_5/loss=0.009, env_step=9000, len=36, n/ep=0, n/st=10, rew=168.50]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #9: test_reward: 204.725000 ± 162.076658, best_reward: 204.725000 ± 162.076658 in #9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #10: 1001it [00:00, 1532.54it/s, agent_1/loss=338.839, agent_2/loss=877.634, agent_3/loss=601.891, agent_4/loss=676.436, agent_5/loss=0.012, env_step=10000, len=48, n/ep=2, n/st=10, rew=208.62]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #10: test_reward: 234.200000 ± 163.632660, best_reward: 234.200000 ± 163.632660 in #10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #11: 1001it [00:00, 1603.39it/s, agent_1/loss=419.971, agent_2/loss=684.372, agent_3/loss=545.245, agent_4/loss=679.703, agent_5/loss=0.027, env_step=11000, len=26, n/ep=0, n/st=10, rew=155.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #11: test_reward: 147.325000 ± 111.450889, best_reward: 234.200000 ± 163.632660 in #10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #12: 1001it [00:00, 1699.69it/s, agent_1/loss=501.239, agent_2/loss=608.142, agent_3/loss=745.933, agent_4/loss=481.709, agent_5/loss=0.022, env_step=12000, len=21, n/ep=1, n/st=10, rew=209.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #12: test_reward: 147.325000 ± 111.450889, best_reward: 234.200000 ± 163.632660 in #10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #13: 1001it [00:00, 1640.72it/s, agent_1/loss=463.260, agent_2/loss=798.858, agent_3/loss=848.077, agent_4/loss=520.053, agent_5/loss=0.020, env_step=13000, len=11, n/ep=0, n/st=10, rew=104.50]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #13: test_reward: 147.325000 ± 111.450889, best_reward: 234.200000 ± 163.632660 in #10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #14: 1001it [00:00, 1628.18it/s, agent_1/loss=380.429, agent_2/loss=805.341, agent_3/loss=966.409, agent_4/loss=580.347, agent_5/loss=0.023, env_step=14000, len=36, n/ep=0, n/st=10, rew=-3.50]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #14: test_reward: 147.325000 ± 111.450889, best_reward: 234.200000 ± 163.632660 in #10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #15: 1001it [00:00, 1004.89it/s, agent_1/loss=209.448, agent_2/loss=1122.104, agent_3/loss=1028.358, agent_4/loss=869.789, agent_5/loss=0.020, env_step=15000, len=6, n/ep=0, n/st=10, rew=171.50]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #15: test_reward: 221.050000 ± 178.111089, best_reward: 234.200000 ± 163.632660 in #10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #16: 1001it [00:00, 1568.33it/s, agent_1/loss=250.346, agent_2/loss=980.647, agent_3/loss=876.027, agent_4/loss=706.553, agent_5/loss=0.021, env_step=16000, len=61, n/ep=0, n/st=10, rew=325.25]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #16: test_reward: 234.200000 ± 163.632660, best_reward: 234.200000 ± 163.632660 in #10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #17: 1001it [00:00, 1576.61it/s, agent_1/loss=180.740, agent_2/loss=915.846, agent_3/loss=943.229, agent_4/loss=965.336, agent_5/loss=0.034, env_step=17000, len=41, n/ep=0, n/st=10, rew=-4.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #17: test_reward: 204.725000 ± 162.076658, best_reward: 234.200000 ± 163.632660 in #10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #18: 1001it [00:00, 1707.48it/s, agent_1/loss=233.586, agent_2/loss=863.164, agent_3/loss=910.125, agent_4/loss=856.334, agent_5/loss=0.035, env_step=18000, len=101, n/ep=1, n/st=10, rew=89.25]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #18: test_reward: 223.225000 ± 182.351428, best_reward: 234.200000 ± 163.632660 in #10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #19: 1001it [00:00, 1684.07it/s, agent_1/loss=290.976, agent_2/loss=1149.420, agent_3/loss=831.118, agent_4/loss=767.110, agent_5/loss=0.031, env_step=19000, len=16, n/ep=0, n/st=10, rew=170.50]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #19: test_reward: 214.325000 ± 202.766462, best_reward: 234.200000 ± 163.632660 in #10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #20: 1001it [00:00, 1431.89it/s, agent_1/loss=259.736, agent_2/loss=989.343, agent_3/loss=770.188, agent_4/loss=859.180, agent_5/loss=0.028, env_step=20000, len=11, n/ep=1, n/st=10, rew=171.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #20: test_reward: 263.850000 ± 209.303822, best_reward: 263.850000 ± 209.303822 in #20\n",
      "Final state:\n",
      "[[1 0 0 0 1]\n",
      " [0 1 0 0 0]\n",
      " [0 0 1 0 0]\n",
      " [0 0 0 1 0]\n",
      " [1 0 0 0 1]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #1: 1001it [00:00, 1337.57it/s, agent_1/loss=803.709, agent_2/loss=1056.976, agent_3/loss=817.635, agent_4/loss=728.474, agent_5/loss=0.028, env_step=1000, len=0, n/ep=0, n/st=10, rew=0.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #1: test_reward: -996.125000 ± 170.765309, best_reward: -996.125000 ± 170.765309 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #2: 1001it [00:00, 1536.91it/s, agent_1/loss=633.476, agent_2/loss=1058.518, agent_3/loss=620.330, agent_4/loss=514.831, agent_5/loss=0.001, env_step=2000, len=38, n/ep=0, n/st=10, rew=160.88]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #2: test_reward: 55.325000 ± 69.366243, best_reward: 55.325000 ± 69.366243 in #2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #3: 1001it [00:00, 1556.57it/s, agent_1/loss=537.121, agent_2/loss=1196.292, agent_3/loss=1076.094, agent_4/loss=898.463, agent_5/loss=0.000, env_step=3000, len=6, n/ep=1, n/st=10, rew=146.50]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #3: test_reward: 86.525000 ± 67.233218, best_reward: 86.525000 ± 67.233218 in #3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #4: 1001it [00:00, 1669.71it/s, agent_1/loss=382.859, agent_2/loss=1083.787, agent_3/loss=1270.344, agent_4/loss=774.221, agent_5/loss=0.006, env_step=4000, len=26, n/ep=0, n/st=10, rew=101.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #4: test_reward: 35.100000 ± 50.700986, best_reward: 86.525000 ± 67.233218 in #3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #5: 1001it [00:00, 1662.95it/s, agent_1/loss=387.721, agent_2/loss=860.141, agent_3/loss=1010.646, agent_4/loss=856.082, agent_5/loss=0.007, env_step=5000, len=1, n/ep=1, n/st=10, rew=0.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #5: test_reward: 78.650000 ± 70.400302, best_reward: 86.525000 ± 67.233218 in #3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #6: 1001it [00:00, 1538.01it/s, agent_1/loss=455.727, agent_2/loss=897.703, agent_3/loss=1047.368, agent_4/loss=871.158, agent_5/loss=0.009, env_step=6000, len=21, n/ep=1, n/st=10, rew=101.50]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #6: test_reward: 123.950000 ± 47.393275, best_reward: 123.950000 ± 47.393275 in #6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #7: 1001it [00:00, 1231.23it/s, agent_1/loss=533.507, agent_2/loss=975.077, agent_3/loss=1115.467, agent_4/loss=806.598, agent_5/loss=0.014, env_step=7000, len=21, n/ep=0, n/st=10, rew=130.50]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #7: test_reward: 93.050000 ± 88.428629, best_reward: 123.950000 ± 47.393275 in #6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #8: 1001it [00:00, 1437.86it/s, agent_1/loss=380.665, agent_2/loss=759.618, agent_3/loss=1171.756, agent_4/loss=743.494, agent_5/loss=0.014, env_step=8000, len=11, n/ep=0, n/st=10, rew=150.88]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #8: test_reward: 161.650000 ± 124.948499, best_reward: 161.650000 ± 124.948499 in #8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #9: 1001it [00:00, 1657.63it/s, agent_1/loss=366.470, agent_2/loss=756.465, agent_3/loss=1397.923, agent_4/loss=809.749, agent_5/loss=0.012, env_step=9000, len=56, n/ep=0, n/st=10, rew=182.25]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #9: test_reward: 161.650000 ± 124.948499, best_reward: 161.650000 ± 124.948499 in #8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #10: 1001it [00:00, 1672.03it/s, agent_1/loss=374.146, agent_2/loss=725.255, agent_3/loss=1520.215, agent_4/loss=1038.619, agent_5/loss=0.020, env_step=10000, len=6, n/ep=1, n/st=10, rew=146.50]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #10: test_reward: 161.650000 ± 124.948499, best_reward: 161.650000 ± 124.948499 in #8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #11: 1001it [00:00, 1630.16it/s, agent_1/loss=363.344, agent_2/loss=963.857, agent_3/loss=1079.516, agent_4/loss=1717.175, agent_5/loss=0.026, env_step=11000, len=16, n/ep=1, n/st=10, rew=208.75]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #11: test_reward: 209.825000 ± 129.585110, best_reward: 209.825000 ± 129.585110 in #11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #12: 1001it [00:00, 1530.78it/s, agent_1/loss=472.151, agent_2/loss=955.902, agent_3/loss=1176.013, agent_4/loss=1588.897, agent_5/loss=0.021, env_step=12000, len=6, n/ep=1, n/st=10, rew=146.50]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #12: test_reward: 276.700000 ± 132.555592, best_reward: 276.700000 ± 132.555592 in #12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #13: 1001it [00:00, 1676.12it/s, agent_1/loss=490.872, agent_2/loss=878.930, agent_3/loss=1121.416, agent_4/loss=1418.019, agent_5/loss=0.023, env_step=13000, len=21, n/ep=0, n/st=10, rew=145.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #13: test_reward: 227.125000 ± 111.279785, best_reward: 276.700000 ± 132.555592 in #12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #14: 1001it [00:00, 1675.38it/s, agent_1/loss=374.452, agent_2/loss=867.159, agent_3/loss=1218.679, agent_4/loss=1408.183, agent_5/loss=0.029, env_step=14000, len=56, n/ep=0, n/st=10, rew=458.50]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #14: test_reward: 277.625000 ± 114.652423, best_reward: 277.625000 ± 114.652423 in #14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #15: 1001it [00:00, 1678.52it/s, agent_1/loss=366.014, agent_2/loss=974.210, agent_3/loss=988.580, agent_4/loss=1352.806, agent_5/loss=0.029, env_step=15000, len=16, n/ep=1, n/st=10, rew=399.25]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #15: test_reward: 188.825000 ± 120.382881, best_reward: 277.625000 ± 114.652423 in #14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #16: 1001it [00:00, 1670.78it/s, agent_1/loss=489.093, agent_2/loss=1088.012, agent_3/loss=1352.538, agent_4/loss=1286.501, agent_5/loss=0.028, env_step=16000, len=26, n/ep=0, n/st=10, rew=169.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #16: test_reward: 252.425000 ± 160.386644, best_reward: 277.625000 ± 114.652423 in #14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #17: 1001it [00:00, 1680.66it/s, agent_1/loss=692.574, agent_2/loss=1149.498, agent_3/loss=1522.925, agent_4/loss=1391.936, agent_5/loss=0.025, env_step=17000, len=41, n/ep=0, n/st=10, rew=245.25]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #17: test_reward: 406.800000 ± 115.730117, best_reward: 406.800000 ± 115.730117 in #17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #18: 1001it [00:00, 1683.76it/s, agent_1/loss=662.725, agent_2/loss=1210.697, agent_3/loss=1481.445, agent_4/loss=1408.270, agent_5/loss=0.024, env_step=18000, len=46, n/ep=0, n/st=10, rew=782.25]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #18: test_reward: -396.050000 ± 596.320822, best_reward: 406.800000 ± 115.730117 in #17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #19: 1001it [00:00, 1674.37it/s, agent_1/loss=728.191, agent_2/loss=1110.191, agent_3/loss=1512.370, agent_4/loss=1286.986, agent_5/loss=0.020, env_step=19000, len=26, n/ep=0, n/st=10, rew=-2.50]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #19: test_reward: 250.625000 ± 186.988845, best_reward: 406.800000 ± 115.730117 in #17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #20: 1001it [00:00, 1676.89it/s, agent_1/loss=875.424, agent_2/loss=1260.960, agent_3/loss=1323.698, agent_4/loss=1574.086, agent_5/loss=0.024, env_step=20000, len=36, n/ep=1, n/st=10, rew=383.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #20: test_reward: 351.100000 ± 201.458811, best_reward: 406.800000 ± 115.730117 in #17\n",
      "Final state:\n",
      "[[1 0 0 1 1]\n",
      " [0 1 1 0 0]\n",
      " [0 1 1 1 0]\n",
      " [1 0 1 1 0]\n",
      " [1 0 0 0 1]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #1: 1001it [00:00, 1778.86it/s, agent_1/loss=1113.457, agent_2/loss=1239.732, agent_3/loss=1013.674, agent_4/loss=737.553, agent_5/loss=0.027, env_step=1000, len=0, n/ep=0, n/st=10, rew=0.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #1: test_reward: -947.425000 ± 185.093323, best_reward: -831.175000 ± 249.054764 in #0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #2: 1001it [00:00, 1792.44it/s, agent_1/loss=1139.182, agent_2/loss=1109.900, agent_3/loss=650.969, agent_4/loss=703.666, agent_5/loss=0.001, env_step=2000, len=0, n/ep=0, n/st=10, rew=0.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #2: test_reward: -916.750000 ± 216.738610, best_reward: -831.175000 ± 249.054764 in #0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #3: 1001it [00:00, 1648.69it/s, agent_1/loss=1079.845, agent_2/loss=1417.457, agent_3/loss=1017.229, agent_4/loss=688.210, agent_5/loss=0.001, env_step=3000, len=26, n/ep=0, n/st=10, rew=155.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #3: test_reward: -215.150000 ± 594.449895, best_reward: -215.150000 ± 594.449895 in #3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #4: 1001it [00:00, 1697.97it/s, agent_1/loss=897.111, agent_2/loss=1908.490, agent_3/loss=1351.284, agent_4/loss=1183.923, agent_5/loss=0.006, env_step=4000, len=6, n/ep=0, n/st=10, rew=-0.50]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #4: test_reward: 169.625000 ± 48.587453, best_reward: 169.625000 ± 48.587453 in #4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #5: 1001it [00:00, 1681.54it/s, agent_1/loss=1145.320, agent_2/loss=1185.872, agent_3/loss=1059.824, agent_4/loss=1569.755, agent_5/loss=0.005, env_step=5000, len=31, n/ep=0, n/st=10, rew=154.50]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #5: test_reward: 133.225000 ± 87.869964, best_reward: 169.625000 ± 48.587453 in #4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #6: 1001it [00:00, 1680.05it/s, agent_1/loss=1339.960, agent_2/loss=1130.839, agent_3/loss=2245.406, agent_4/loss=1620.101, agent_5/loss=0.008, env_step=6000, len=6, n/ep=0, n/st=10, rew=171.50]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #6: test_reward: 181.925000 ± 99.859529, best_reward: 181.925000 ± 99.859529 in #6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #7: 1001it [00:00, 1679.73it/s, agent_1/loss=1375.306, agent_2/loss=1227.722, agent_3/loss=1787.932, agent_4/loss=1943.610, agent_5/loss=0.010, env_step=7000, len=21, n/ep=0, n/st=10, rew=134.62]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #7: test_reward: 209.700000 ± 139.570314, best_reward: 209.700000 ± 139.570314 in #7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #8: 1001it [00:00, 1493.74it/s, agent_1/loss=1711.873, agent_2/loss=764.388, agent_3/loss=1417.696, agent_4/loss=1806.752, agent_5/loss=0.010, env_step=8000, len=16, n/ep=1, n/st=10, rew=377.75]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #8: test_reward: -228.750000 ± 607.305813, best_reward: 209.700000 ± 139.570314 in #7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #9: 1001it [00:00, 1695.80it/s, agent_1/loss=1842.870, agent_2/loss=1117.999, agent_3/loss=1501.870, agent_4/loss=1840.724, agent_5/loss=0.012, env_step=9000, len=11, n/ep=0, n/st=10, rew=-1.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #9: test_reward: -404.700000 ± 398.910012, best_reward: 209.700000 ± 139.570314 in #7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #10: 1001it [00:00, 1704.29it/s, agent_1/loss=1407.664, agent_2/loss=1043.266, agent_3/loss=1701.267, agent_4/loss=1985.501, agent_5/loss=0.012, env_step=10000, len=11, n/ep=1, n/st=10, rew=210.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #10: test_reward: 231.175000 ± 170.128189, best_reward: 231.175000 ± 170.128189 in #10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #11: 1001it [00:00, 1672.53it/s, agent_1/loss=886.050, agent_2/loss=781.518, agent_3/loss=1738.910, agent_4/loss=2435.401, agent_5/loss=0.013, env_step=11000, len=31, n/ep=0, n/st=10, rew=280.25]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #11: test_reward: 252.500000 ± 147.978884, best_reward: 252.500000 ± 147.978884 in #11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #12: 1001it [00:00, 1692.95it/s, agent_1/loss=1006.777, agent_2/loss=971.048, agent_3/loss=1716.586, agent_4/loss=2046.041, agent_5/loss=0.017, env_step=12000, len=28, n/ep=2, n/st=10, rew=-2.75]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #12: test_reward: 252.500000 ± 147.978884, best_reward: 252.500000 ± 147.978884 in #11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #13: 1001it [00:00, 1667.68it/s, agent_1/loss=845.062, agent_2/loss=1026.374, agent_3/loss=1673.275, agent_4/loss=1934.326, agent_5/loss=0.015, env_step=13000, len=41, n/ep=0, n/st=10, rew=475.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #13: test_reward: 252.500000 ± 147.978884, best_reward: 252.500000 ± 147.978884 in #11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #14: 1001it [00:00, 1547.86it/s, agent_1/loss=705.119, agent_2/loss=1229.902, agent_3/loss=1388.982, agent_4/loss=2082.673, agent_5/loss=0.013, env_step=14000, len=26, n/ep=0, n/st=10, rew=230.25]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #14: test_reward: 248.600000 ± 149.644378, best_reward: 252.500000 ± 147.978884 in #11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #15: 1001it [00:00, 1681.35it/s, agent_1/loss=950.585, agent_2/loss=1232.825, agent_3/loss=1532.123, agent_4/loss=1928.766, agent_5/loss=0.013, env_step=15000, len=36, n/ep=0, n/st=10, rew=255.25]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #15: test_reward: 275.600000 ± 179.339908, best_reward: 275.600000 ± 179.339908 in #15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #16: 1001it [00:00, 1689.08it/s, agent_1/loss=1031.739, agent_2/loss=1051.217, agent_3/loss=1523.206, agent_4/loss=1857.758, agent_5/loss=0.016, env_step=16000, len=11, n/ep=0, n/st=10, rew=378.25]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #16: test_reward: -120.175000 ± 445.174012, best_reward: 275.600000 ± 179.339908 in #15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #17: 1001it [00:00, 1593.07it/s, agent_1/loss=939.792, agent_2/loss=1225.855, agent_3/loss=1466.301, agent_4/loss=1815.109, agent_5/loss=0.016, env_step=17000, len=16, n/ep=0, n/st=10, rew=424.25]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #17: test_reward: 30.700000 ± 500.144989, best_reward: 275.600000 ± 179.339908 in #15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #18: 1001it [00:00, 1579.18it/s, agent_1/loss=802.995, agent_2/loss=1227.319, agent_3/loss=1284.698, agent_4/loss=1462.254, agent_5/loss=0.015, env_step=18000, len=36, n/ep=0, n/st=10, rew=229.25]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #18: test_reward: 377.575000 ± 84.191304, best_reward: 377.575000 ± 84.191304 in #18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #19: 1001it [00:00, 1688.18it/s, agent_1/loss=804.459, agent_2/loss=1387.633, agent_3/loss=1084.773, agent_4/loss=1887.697, agent_5/loss=0.015, env_step=19000, len=31, n/ep=0, n/st=10, rew=284.75]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #19: test_reward: 414.750000 ± 59.853049, best_reward: 414.750000 ± 59.853049 in #19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #20: 1001it [00:00, 1681.96it/s, agent_1/loss=995.171, agent_2/loss=1494.338, agent_3/loss=1271.197, agent_4/loss=2008.074, agent_5/loss=0.017, env_step=20000, len=23, n/ep=0, n/st=10, rew=396.25]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #20: test_reward: 399.750000 ± 58.023487, best_reward: 414.750000 ± 59.853049 in #19\n",
      "Final state:\n",
      "[[1 1 1 1 1]\n",
      " [1 1 0 1 1]\n",
      " [1 0 1 1 1]\n",
      " [1 1 1 1 1]\n",
      " [1 1 1 1 1]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #1: 1001it [00:00, 1901.08it/s, agent_1/loss=963.790, agent_2/loss=1331.558, agent_3/loss=946.430, agent_4/loss=735.827, agent_5/loss=0.029, env_step=1000, len=0, n/ep=0, n/st=10, rew=0.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #1: test_reward: -888.025000 ± 182.839733, best_reward: -868.400000 ± 245.033600 in #0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #2: 1001it [00:00, 1907.84it/s, agent_1/loss=900.189, agent_2/loss=1370.336, agent_3/loss=533.902, agent_4/loss=638.452, agent_5/loss=0.001, env_step=2000, len=0, n/ep=0, n/st=10, rew=0.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #2: test_reward: -684.900000 ± 201.856050, best_reward: -684.900000 ± 201.856050 in #2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #3: 1001it [00:00, 1831.25it/s, agent_1/loss=796.516, agent_2/loss=841.517, agent_3/loss=690.961, agent_4/loss=348.763, agent_5/loss=0.001, env_step=3000, len=26, n/ep=1, n/st=10, rew=155.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #3: test_reward: 115.125000 ± 105.799649, best_reward: 115.125000 ± 105.799649 in #3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #4: 1001it [00:00, 1697.48it/s, agent_1/loss=1132.959, agent_2/loss=1731.557, agent_3/loss=1097.465, agent_4/loss=1013.127, agent_5/loss=0.005, env_step=4000, len=11, n/ep=1, n/st=10, rew=171.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #4: test_reward: 78.250000 ± 79.734638, best_reward: 115.125000 ± 105.799649 in #3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #5: 1001it [00:00, 1521.76it/s, agent_1/loss=1023.687, agent_2/loss=1956.814, agent_3/loss=757.243, agent_4/loss=957.256, agent_5/loss=0.003, env_step=5000, len=1, n/ep=1, n/st=10, rew=0.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #5: test_reward: 122.125000 ± 98.583800, best_reward: 122.125000 ± 98.583800 in #5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #6: 1001it [00:00, 1696.15it/s, agent_1/loss=462.598, agent_2/loss=1588.958, agent_3/loss=506.808, agent_4/loss=403.016, agent_5/loss=0.002, env_step=6000, len=18, n/ep=0, n/st=10, rew=74.62]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #6: test_reward: 119.025000 ± 91.980735, best_reward: 122.125000 ± 98.583800 in #5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #7: 1001it [00:00, 1693.33it/s, agent_1/loss=511.831, agent_2/loss=1062.009, agent_3/loss=881.421, agent_4/loss=839.147, agent_5/loss=0.003, env_step=7000, len=6, n/ep=1, n/st=10, rew=-0.50]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #7: test_reward: 118.600000 ± 115.975547, best_reward: 122.125000 ± 98.583800 in #5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #8: 1001it [00:00, 1700.68it/s, agent_1/loss=1013.785, agent_2/loss=1210.461, agent_3/loss=884.187, agent_4/loss=947.263, agent_5/loss=0.009, env_step=8000, len=21, n/ep=0, n/st=10, rew=387.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #8: test_reward: 208.750000 ± 117.771123, best_reward: 208.750000 ± 117.771123 in #8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #9: 1001it [00:00, 1708.33it/s, agent_1/loss=1188.256, agent_2/loss=1459.870, agent_3/loss=1141.421, agent_4/loss=860.930, agent_5/loss=0.012, env_step=9000, len=11, n/ep=0, n/st=10, rew=156.50]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #9: test_reward: 203.400000 ± 111.144793, best_reward: 208.750000 ± 117.771123 in #8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #10: 1001it [00:00, 1723.36it/s, agent_1/loss=1053.936, agent_2/loss=1348.984, agent_3/loss=1676.803, agent_4/loss=957.724, agent_5/loss=0.016, env_step=10000, len=26, n/ep=0, n/st=10, rew=495.50]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #10: test_reward: -386.150000 ± 479.497422, best_reward: 208.750000 ± 117.771123 in #8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #11: 1001it [00:00, 1687.59it/s, agent_1/loss=625.920, agent_2/loss=1075.928, agent_3/loss=1571.550, agent_4/loss=1158.474, agent_5/loss=0.012, env_step=11000, len=21, n/ep=1, n/st=10, rew=297.75]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #11: test_reward: 237.925000 ± 135.163006, best_reward: 237.925000 ± 135.163006 in #11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #12: 1001it [00:00, 1704.06it/s, agent_1/loss=754.724, agent_2/loss=1167.590, agent_3/loss=1566.675, agent_4/loss=1110.235, agent_5/loss=0.013, env_step=12000, len=16, n/ep=0, n/st=10, rew=387.50]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #12: test_reward: 229.450000 ± 124.462886, best_reward: 237.925000 ± 135.163006 in #11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #13: 1001it [00:00, 1686.29it/s, agent_1/loss=911.354, agent_2/loss=1041.017, agent_3/loss=1107.634, agent_4/loss=859.198, agent_5/loss=0.011, env_step=13000, len=13, n/ep=2, n/st=10, rew=382.88]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #13: test_reward: 208.750000 ± 117.771123, best_reward: 237.925000 ± 135.163006 in #11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #14: 1001it [00:00, 1674.65it/s, agent_1/loss=764.647, agent_2/loss=1111.794, agent_3/loss=1116.017, agent_4/loss=819.743, agent_5/loss=0.010, env_step=14000, len=16, n/ep=1, n/st=10, rew=165.75]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #14: test_reward: 237.925000 ± 135.163006, best_reward: 237.925000 ± 135.163006 in #11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #15: 1001it [00:00, 1678.76it/s, agent_1/loss=1045.860, agent_2/loss=1089.758, agent_3/loss=1482.111, agent_4/loss=622.956, agent_5/loss=0.010, env_step=15000, len=11, n/ep=1, n/st=10, rew=327.75]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #15: test_reward: 236.425000 ± 137.963086, best_reward: 237.925000 ± 135.163006 in #11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #16: 1001it [00:00, 1561.05it/s, agent_1/loss=872.180, agent_2/loss=1128.746, agent_3/loss=1723.543, agent_4/loss=827.530, agent_5/loss=0.018, env_step=16000, len=16, n/ep=0, n/st=10, rew=165.75]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #16: test_reward: 221.300000 ± 135.284413, best_reward: 237.925000 ± 135.163006 in #11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #17: 1001it [00:00, 1676.73it/s, agent_1/loss=487.962, agent_2/loss=656.057, agent_3/loss=2276.082, agent_4/loss=1045.440, agent_5/loss=0.016, env_step=17000, len=6, n/ep=1, n/st=10, rew=-0.50]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #17: test_reward: 235.400000 ± 66.342878, best_reward: 237.925000 ± 135.163006 in #11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #18: 1001it [00:00, 1701.53it/s, agent_1/loss=493.549, agent_2/loss=685.504, agent_3/loss=2007.666, agent_4/loss=1125.308, agent_5/loss=0.015, env_step=18000, len=26, n/ep=1, n/st=10, rew=282.75]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #18: test_reward: 238.400000 ± 78.810548, best_reward: 238.400000 ± 78.810548 in #18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #19: 1001it [00:00, 1683.59it/s, agent_1/loss=425.316, agent_2/loss=765.199, agent_3/loss=1856.345, agent_4/loss=965.982, agent_5/loss=0.016, env_step=19000, len=31, n/ep=0, n/st=10, rew=331.88]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #19: test_reward: 244.700000 ± 114.103287, best_reward: 244.700000 ± 114.103287 in #19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #20: 1001it [00:00, 1662.19it/s, agent_1/loss=398.900, agent_2/loss=1356.566, agent_3/loss=1842.990, agent_4/loss=1405.319, agent_5/loss=0.013, env_step=20000, len=11, n/ep=0, n/st=10, rew=-1.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #20: test_reward: 255.625000 ± 64.437494, best_reward: 255.625000 ± 64.437494 in #20\n",
      "Final state:\n",
      "[[1 0 0 1 1]\n",
      " [0 1 0 1 0]\n",
      " [0 0 1 1 0]\n",
      " [1 1 1 1 0]\n",
      " [1 0 0 0 1]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #1: 1001it [00:00, 1869.66it/s, agent_1/loss=992.679, agent_2/loss=1257.791, agent_3/loss=857.658, agent_4/loss=752.351, agent_5/loss=0.029, env_step=1000, len=0, n/ep=0, n/st=10, rew=0.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #1: test_reward: -1003.400000 ± 208.896123, best_reward: -946.600000 ± 258.074267 in #0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #2: 1001it [00:00, 1887.52it/s, agent_1/loss=1070.878, agent_2/loss=1338.941, agent_3/loss=619.841, agent_4/loss=670.246, agent_5/loss=0.001, env_step=2000, len=0, n/ep=0, n/st=10, rew=0.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #2: test_reward: -968.750000 ± 119.994219, best_reward: -946.600000 ± 258.074267 in #0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #3: 1001it [00:00, 1800.72it/s, agent_1/loss=1395.141, agent_2/loss=1116.632, agent_3/loss=892.204, agent_4/loss=383.778, agent_5/loss=0.001, env_step=3000, len=12, n/ep=0, n/st=10, rew=151.50]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #3: test_reward: -891.175000 ± 580.121281, best_reward: -891.175000 ± 580.121281 in #3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #4: 1001it [00:00, 1705.35it/s, agent_1/loss=1917.428, agent_2/loss=1174.883, agent_3/loss=1700.038, agent_4/loss=556.491, agent_5/loss=0.006, env_step=4000, len=11, n/ep=0, n/st=10, rew=362.25]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #4: test_reward: 8.325000 ± 520.270015, best_reward: 8.325000 ± 520.270015 in #4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #5: 1001it [00:00, 1665.37it/s, agent_1/loss=1920.840, agent_2/loss=1137.382, agent_3/loss=2772.993, agent_4/loss=986.326, agent_5/loss=0.004, env_step=5000, len=23, n/ep=0, n/st=10, rew=252.88]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #5: test_reward: 145.800000 ± 169.576450, best_reward: 145.800000 ± 169.576450 in #5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #6: 1001it [00:00, 1664.42it/s, agent_1/loss=643.336, agent_2/loss=1053.911, agent_3/loss=2449.451, agent_4/loss=329.026, agent_5/loss=0.003, env_step=6000, len=1, n/ep=1, n/st=10, rew=0.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #6: test_reward: 85.075000 ± 85.453207, best_reward: 145.800000 ± 169.576450 in #5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #7: 1001it [00:00, 1529.05it/s, agent_1/loss=799.150, agent_2/loss=960.370, agent_3/loss=1479.934, agent_4/loss=241.795, agent_5/loss=0.004, env_step=7000, len=6, n/ep=2, n/st=10, rew=165.12]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #7: test_reward: 85.075000 ± 85.453207, best_reward: 145.800000 ± 169.576450 in #5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #8: 1001it [00:00, 1659.07it/s, agent_1/loss=832.714, agent_2/loss=973.595, agent_3/loss=1076.059, agent_4/loss=543.271, agent_5/loss=0.005, env_step=8000, len=11, n/ep=1, n/st=10, rew=192.75]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #8: test_reward: 91.650000 ± 108.039646, best_reward: 145.800000 ± 169.576450 in #5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #9: 1001it [00:00, 1663.64it/s, agent_1/loss=1095.187, agent_2/loss=926.966, agent_3/loss=924.934, agent_4/loss=1020.450, agent_5/loss=0.010, env_step=9000, len=16, n/ep=0, n/st=10, rew=156.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #9: test_reward: -623.925000 ± 649.616474, best_reward: 145.800000 ± 169.576450 in #5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #10: 1001it [00:00, 1680.58it/s, agent_1/loss=2040.934, agent_2/loss=1228.698, agent_3/loss=1416.982, agent_4/loss=882.805, agent_5/loss=0.012, env_step=10000, len=11, n/ep=0, n/st=10, rew=192.75]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #10: test_reward: -1202.525000 ± 100.408133, best_reward: 145.800000 ± 169.576450 in #5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #11: 1001it [00:00, 1407.14it/s, agent_1/loss=1735.177, agent_2/loss=941.846, agent_3/loss=1534.579, agent_4/loss=1022.829, agent_5/loss=0.014, env_step=11000, len=11, n/ep=0, n/st=10, rew=192.75]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #11: test_reward: -1212.725000 ± 92.508138, best_reward: 145.800000 ± 169.576450 in #5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #12: 1001it [00:00, 1605.27it/s, agent_1/loss=1619.247, agent_2/loss=781.417, agent_3/loss=1160.922, agent_4/loss=934.973, agent_5/loss=0.013, env_step=12000, len=11, n/ep=0, n/st=10, rew=192.75]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #12: test_reward: -1190.050000 ± 100.056659, best_reward: 145.800000 ± 169.576450 in #5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #13: 1001it [00:00, 1710.27it/s, agent_1/loss=1352.790, agent_2/loss=799.721, agent_3/loss=1209.903, agent_4/loss=751.605, agent_5/loss=0.012, env_step=13000, len=11, n/ep=0, n/st=10, rew=192.75]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #13: test_reward: -1234.275000 ± 89.940915, best_reward: 145.800000 ± 169.576450 in #5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #14: 1001it [00:00, 1625.82it/s, agent_1/loss=1254.559, agent_2/loss=573.090, agent_3/loss=1088.573, agent_4/loss=459.928, agent_5/loss=0.012, env_step=14000, len=36, n/ep=0, n/st=10, rew=108.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #14: test_reward: -302.450000 ± 715.793841, best_reward: 145.800000 ± 169.576450 in #5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #15: 1001it [00:00, 1253.63it/s, agent_1/loss=1202.712, agent_2/loss=645.728, agent_3/loss=1338.334, agent_4/loss=918.839, agent_5/loss=0.016, env_step=15000, len=41, n/ep=0, n/st=10, rew=252.25]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #15: test_reward: -853.825000 ± 427.010920, best_reward: 145.800000 ± 169.576450 in #5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #16: 1001it [00:00, 1625.98it/s, agent_1/loss=1279.313, agent_2/loss=712.436, agent_3/loss=1216.360, agent_4/loss=1055.122, agent_5/loss=0.016, env_step=16000, len=41, n/ep=0, n/st=10, rew=252.25]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #16: test_reward: -1227.800000 ± 82.434049, best_reward: 145.800000 ± 169.576450 in #5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #17: 1001it [00:00, 1658.23it/s, agent_1/loss=1073.254, agent_2/loss=757.648, agent_3/loss=1169.921, agent_4/loss=1033.968, agent_5/loss=0.022, env_step=17000, len=13, n/ep=0, n/st=10, rew=173.12]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #17: test_reward: 227.775000 ± 97.836499, best_reward: 227.775000 ± 97.836499 in #17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #18: 1001it [00:00, 1557.17it/s, agent_1/loss=786.844, agent_2/loss=604.838, agent_3/loss=1173.664, agent_4/loss=833.562, agent_5/loss=0.019, env_step=18000, len=11, n/ep=1, n/st=10, rew=429.25]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #18: test_reward: 76.175000 ± 468.033920, best_reward: 227.775000 ± 97.836499 in #17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #19: 1001it [00:00, 1697.57it/s, agent_1/loss=1067.949, agent_2/loss=776.868, agent_3/loss=1339.881, agent_4/loss=858.985, agent_5/loss=0.022, env_step=19000, len=96, n/ep=0, n/st=10, rew=223.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #19: test_reward: 41.300000 ± 325.941479, best_reward: 227.775000 ± 97.836499 in #17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #20: 1001it [00:00, 1664.80it/s, agent_1/loss=872.979, agent_2/loss=855.894, agent_3/loss=885.121, agent_4/loss=929.631, agent_5/loss=0.023, env_step=20000, len=21, n/ep=1, n/st=10, rew=428.25]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #20: test_reward: 288.825000 ± 107.359737, best_reward: 288.825000 ± 107.359737 in #20\n",
      "Final state:\n",
      "[[1 1 0 1 1]\n",
      " [1 1 1 1 1]\n",
      " [0 1 1 1 1]\n",
      " [1 1 1 1 0]\n",
      " [1 1 1 0 1]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #1: 1001it [00:00, 1883.58it/s, agent_1/loss=809.357, agent_2/loss=1285.561, agent_3/loss=768.358, agent_4/loss=781.035, agent_5/loss=0.029, env_step=1000, len=0, n/ep=0, n/st=10, rew=0.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #1: test_reward: -934.500000 ± 122.791795, best_reward: -792.300000 ± 250.917561 in #0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #2: 1001it [00:00, 1872.84it/s, agent_1/loss=1038.850, agent_2/loss=950.831, agent_3/loss=704.266, agent_4/loss=647.725, agent_5/loss=0.001, env_step=2000, len=0, n/ep=0, n/st=10, rew=0.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #2: test_reward: -839.125000 ± 117.590882, best_reward: -792.300000 ± 250.917561 in #0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #3: 1001it [00:00, 1713.57it/s, agent_1/loss=1612.304, agent_2/loss=1339.301, agent_3/loss=1200.857, agent_4/loss=739.525, agent_5/loss=0.001, env_step=3000, len=16, n/ep=1, n/st=10, rew=467.50]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #3: test_reward: 243.925000 ± 100.876908, best_reward: 243.925000 ± 100.876908 in #3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #4: 1001it [00:00, 1631.20it/s, agent_1/loss=3084.291, agent_2/loss=2474.888, agent_3/loss=1884.119, agent_4/loss=1150.809, agent_5/loss=0.003, env_step=4000, len=2, n/ep=3, n/st=10, rew=-0.17]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #4: test_reward: 57.050000 ± 69.989803, best_reward: 243.925000 ± 100.876908 in #3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #5: 1001it [00:00, 1643.59it/s, agent_1/loss=938.068, agent_2/loss=1248.888, agent_3/loss=1630.952, agent_4/loss=1571.182, agent_5/loss=0.003, env_step=5000, len=6, n/ep=2, n/st=10, rew=73.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #5: test_reward: 64.275000 ± 111.641527, best_reward: 243.925000 ± 100.876908 in #3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #6: 1001it [00:00, 1646.12it/s, agent_1/loss=783.135, agent_2/loss=742.425, agent_3/loss=653.776, agent_4/loss=181.125, agent_5/loss=0.001, env_step=6000, len=6, n/ep=1, n/st=10, rew=146.50]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #6: test_reward: 112.000000 ± 75.850181, best_reward: 243.925000 ± 100.876908 in #3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #7: 1001it [00:00, 1536.64it/s, agent_1/loss=972.128, agent_2/loss=2369.823, agent_3/loss=1246.606, agent_4/loss=2231.128, agent_5/loss=0.009, env_step=7000, len=6, n/ep=0, n/st=10, rew=146.50]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #7: test_reward: -885.125000 ± 168.948633, best_reward: 243.925000 ± 100.876908 in #3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #8: 1001it [00:00, 1730.32it/s, agent_1/loss=996.683, agent_2/loss=2322.604, agent_3/loss=1748.231, agent_4/loss=2359.496, agent_5/loss=0.012, env_step=8000, len=6, n/ep=0, n/st=10, rew=146.50]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #8: test_reward: -885.050000 ± 175.139687, best_reward: 243.925000 ± 100.876908 in #3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #9: 1001it [00:00, 1722.85it/s, agent_1/loss=792.233, agent_2/loss=1682.378, agent_3/loss=1525.055, agent_4/loss=1770.000, agent_5/loss=0.010, env_step=9000, len=246, n/ep=1, n/st=10, rew=-402.25]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #9: test_reward: 391.050000 ± 80.686802, best_reward: 391.050000 ± 80.686802 in #9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #10: 1001it [00:00, 1652.25it/s, agent_1/loss=804.422, agent_2/loss=1395.625, agent_3/loss=1431.571, agent_4/loss=1558.348, agent_5/loss=0.008, env_step=10000, len=18, n/ep=0, n/st=10, rew=384.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #10: test_reward: 391.050000 ± 80.686802, best_reward: 391.050000 ± 80.686802 in #9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #11: 1001it [00:00, 1647.72it/s, agent_1/loss=828.185, agent_2/loss=1239.782, agent_3/loss=1261.607, agent_4/loss=1749.402, agent_5/loss=0.015, env_step=11000, len=16, n/ep=4, n/st=10, rew=329.75]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #11: test_reward: 391.050000 ± 80.686802, best_reward: 391.050000 ± 80.686802 in #9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #12: 1001it [00:00, 1656.91it/s, agent_1/loss=968.028, agent_2/loss=1258.039, agent_3/loss=1697.552, agent_4/loss=1507.632, agent_5/loss=0.016, env_step=12000, len=16, n/ep=0, n/st=10, rew=457.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #12: test_reward: 569.025000 ± 74.184858, best_reward: 569.025000 ± 74.184858 in #12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #13: 1001it [00:00, 1626.35it/s, agent_1/loss=987.670, agent_2/loss=1288.965, agent_3/loss=1486.195, agent_4/loss=2048.831, agent_5/loss=0.021, env_step=13000, len=11, n/ep=0, n/st=10, rew=417.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #13: test_reward: 351.425000 ± 65.957188, best_reward: 569.025000 ± 74.184858 in #12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #14: 1001it [00:00, 1697.51it/s, agent_1/loss=1221.802, agent_2/loss=1669.539, agent_3/loss=1739.791, agent_4/loss=1490.476, agent_5/loss=0.017, env_step=14000, len=11, n/ep=0, n/st=10, rew=456.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #14: test_reward: 450.725000 ± 98.979761, best_reward: 569.025000 ± 74.184858 in #12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #15: 1001it [00:00, 1757.03it/s, agent_1/loss=1284.769, agent_2/loss=1594.763, agent_3/loss=1480.512, agent_4/loss=1584.001, agent_5/loss=0.019, env_step=15000, len=81, n/ep=0, n/st=10, rew=296.12]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #15: test_reward: 495.025000 ± 115.553097, best_reward: 569.025000 ± 74.184858 in #12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #16: 1001it [00:00, 1654.74it/s, agent_1/loss=1449.232, agent_2/loss=1278.134, agent_3/loss=1085.962, agent_4/loss=817.178, agent_5/loss=0.013, env_step=16000, len=26, n/ep=1, n/st=10, rew=667.75]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #16: test_reward: 548.625000 ± 142.471280, best_reward: 569.025000 ± 74.184858 in #12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #17: 1001it [00:00, 1583.82it/s, agent_1/loss=1358.055, agent_2/loss=1052.984, agent_3/loss=956.979, agent_4/loss=894.727, agent_5/loss=0.014, env_step=17000, len=18, n/ep=2, n/st=10, rew=486.38]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #17: test_reward: 422.000000 ± 137.580204, best_reward: 569.025000 ± 74.184858 in #12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #18: 1001it [00:00, 1501.25it/s, agent_1/loss=1171.792, agent_2/loss=911.854, agent_3/loss=817.411, agent_4/loss=718.698, agent_5/loss=0.011, env_step=18000, len=13, n/ep=0, n/st=10, rew=487.50]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #18: test_reward: 455.500000 ± 146.525126, best_reward: 569.025000 ± 74.184858 in #12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #19: 1001it [00:00, 1653.02it/s, agent_1/loss=983.624, agent_2/loss=1195.965, agent_3/loss=767.223, agent_4/loss=1203.007, agent_5/loss=0.010, env_step=19000, len=16, n/ep=2, n/st=10, rew=407.62]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #19: test_reward: 534.500000 ± 119.191810, best_reward: 569.025000 ± 74.184858 in #12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #20: 1001it [00:00, 1640.51it/s, agent_1/loss=906.398, agent_2/loss=1189.618, agent_3/loss=607.796, agent_4/loss=1269.056, agent_5/loss=0.008, env_step=20000, len=16, n/ep=0, n/st=10, rew=478.75]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #20: test_reward: 394.100000 ± 152.215070, best_reward: 569.025000 ± 74.184858 in #12\n",
      "Final state:\n",
      "[[1 1 1 1 1]\n",
      " [1 1 1 1 0]\n",
      " [1 1 1 1 0]\n",
      " [1 1 1 1 1]\n",
      " [1 0 0 1 1]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #1: 1001it [00:00, 1904.11it/s, agent_1/loss=1058.070, agent_2/loss=1065.820, agent_3/loss=886.169, agent_4/loss=799.095, agent_5/loss=0.030, env_step=1000, len=0, n/ep=0, n/st=10, rew=0.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #1: test_reward: -937.550000 ± 174.372511, best_reward: -763.550000 ± 243.448629 in #0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #2: 1001it [00:00, 1907.56it/s, agent_1/loss=1187.039, agent_2/loss=1143.499, agent_3/loss=615.624, agent_4/loss=622.334, agent_5/loss=0.001, env_step=2000, len=0, n/ep=0, n/st=10, rew=0.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #2: test_reward: -1077.700000 ± 170.062555, best_reward: -763.550000 ± 243.448629 in #0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #3: 1001it [00:00, 1824.86it/s, agent_1/loss=1531.811, agent_2/loss=1012.899, agent_3/loss=508.599, agent_4/loss=566.919, agent_5/loss=0.000, env_step=3000, len=18, n/ep=2, n/st=10, rew=134.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #3: test_reward: 182.000000 ± 59.521845, best_reward: 182.000000 ± 59.521845 in #3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #4: 1001it [00:00, 1738.65it/s, agent_1/loss=2994.683, agent_2/loss=1198.195, agent_3/loss=1544.486, agent_4/loss=1043.414, agent_5/loss=0.006, env_step=4000, len=11, n/ep=0, n/st=10, rew=156.50]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #4: test_reward: -1280.950000 ± 55.975084, best_reward: 182.000000 ± 59.521845 in #3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #5: 1001it [00:00, 1720.65it/s, agent_1/loss=2653.524, agent_2/loss=776.324, agent_3/loss=2295.414, agent_4/loss=1223.488, agent_5/loss=0.004, env_step=5000, len=11, n/ep=0, n/st=10, rew=174.62]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #5: test_reward: 180.050000 ± 58.975503, best_reward: 182.000000 ± 59.521845 in #3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #6: 1001it [00:00, 1651.31it/s, agent_1/loss=1807.251, agent_2/loss=938.455, agent_3/loss=1565.486, agent_4/loss=1132.161, agent_5/loss=0.004, env_step=6000, len=11, n/ep=0, n/st=10, rew=156.50]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #6: test_reward: 207.200000 ± 81.055213, best_reward: 207.200000 ± 81.055213 in #6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #7: 1001it [00:00, 1688.33it/s, agent_1/loss=2015.305, agent_2/loss=770.267, agent_3/loss=1467.741, agent_4/loss=720.789, agent_5/loss=0.007, env_step=7000, len=6, n/ep=0, n/st=10, rew=-0.50]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #7: test_reward: -1272.000000 ± 59.058022, best_reward: 207.200000 ± 81.055213 in #6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #8: 1001it [00:00, 1818.71it/s, agent_1/loss=1668.768, agent_2/loss=645.318, agent_3/loss=975.488, agent_4/loss=706.988, agent_5/loss=0.010, env_step=8000, len=6, n/ep=0, n/st=10, rew=-0.50]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #8: test_reward: -341.000000 ± 57.981463, best_reward: 207.200000 ± 81.055213 in #6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #9: 1001it [00:00, 1651.94it/s, agent_1/loss=1147.751, agent_2/loss=497.494, agent_3/loss=760.924, agent_4/loss=644.903, agent_5/loss=0.008, env_step=9000, len=6, n/ep=0, n/st=10, rew=-0.50]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #9: test_reward: -338.075000 ± 68.733366, best_reward: 207.200000 ± 81.055213 in #6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #10: 1001it [00:00, 1703.58it/s, agent_1/loss=988.535, agent_2/loss=574.871, agent_3/loss=953.898, agent_4/loss=391.847, agent_5/loss=0.008, env_step=10000, len=6, n/ep=0, n/st=10, rew=-0.50]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #10: test_reward: -1241.850000 ± 82.417246, best_reward: 207.200000 ± 81.055213 in #6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #11: 1001it [00:00, 1563.56it/s, agent_1/loss=827.526, agent_2/loss=303.122, agent_3/loss=806.146, agent_4/loss=428.785, agent_5/loss=0.007, env_step=11000, len=6, n/ep=0, n/st=10, rew=-0.50]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #11: test_reward: -316.850000 ± 88.034666, best_reward: 207.200000 ± 81.055213 in #6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #12: 1001it [00:00, 1766.83it/s, agent_1/loss=750.125, agent_2/loss=203.388, agent_3/loss=853.086, agent_4/loss=412.501, agent_5/loss=0.006, env_step=12000, len=501, n/ep=0, n/st=10, rew=-362.50]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #12: test_reward: -164.425000 ± 108.898580, best_reward: 207.200000 ± 81.055213 in #6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #13: 1001it [00:00, 1768.39it/s, agent_1/loss=726.860, agent_2/loss=212.227, agent_3/loss=790.033, agent_4/loss=428.173, agent_5/loss=0.008, env_step=13000, len=501, n/ep=0, n/st=10, rew=-362.50]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #13: test_reward: -424.025000 ± 212.932015, best_reward: 207.200000 ± 81.055213 in #6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #14: 1001it [00:00, 1786.10it/s, agent_1/loss=515.354, agent_2/loss=282.602, agent_3/loss=683.435, agent_4/loss=396.494, agent_5/loss=0.008, env_step=14000, len=501, n/ep=0, n/st=10, rew=-362.50]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #14: test_reward: -386.800000 ± 245.210542, best_reward: 207.200000 ± 81.055213 in #6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #15: 1001it [00:00, 1691.06it/s, agent_1/loss=506.771, agent_2/loss=227.918, agent_3/loss=500.814, agent_4/loss=281.438, agent_5/loss=0.006, env_step=15000, len=11, n/ep=0, n/st=10, rew=166.50]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #15: test_reward: -148.875000 ± 392.310022, best_reward: 207.200000 ± 81.055213 in #6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #16: 1001it [00:00, 1704.20it/s, agent_1/loss=581.064, agent_2/loss=244.152, agent_3/loss=707.625, agent_4/loss=322.195, agent_5/loss=0.010, env_step=16000, len=16, n/ep=0, n/st=10, rew=374.62]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #16: test_reward: 310.075000 ± 236.890509, best_reward: 310.075000 ± 236.890509 in #16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #17: 1001it [00:00, 1678.05it/s, agent_1/loss=513.344, agent_2/loss=212.248, agent_3/loss=738.309, agent_4/loss=441.416, agent_5/loss=0.015, env_step=17000, len=16, n/ep=0, n/st=10, rew=156.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #17: test_reward: 406.525000 ± 118.599138, best_reward: 406.525000 ± 118.599138 in #17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #18: 1001it [00:00, 1601.92it/s, agent_1/loss=554.997, agent_2/loss=328.396, agent_3/loss=469.825, agent_4/loss=461.696, agent_5/loss=0.010, env_step=18000, len=26, n/ep=0, n/st=10, rew=408.75]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #18: test_reward: 581.975000 ± 76.921669, best_reward: 581.975000 ± 76.921669 in #18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #19: 1001it [00:00, 1666.34it/s, agent_1/loss=425.114, agent_2/loss=352.908, agent_3/loss=508.161, agent_4/loss=954.264, agent_5/loss=0.009, env_step=19000, len=16, n/ep=1, n/st=10, rew=624.50]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #19: test_reward: 631.000000 ± 21.307276, best_reward: 631.000000 ± 21.307276 in #19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #20: 1001it [00:00, 1492.68it/s, agent_1/loss=601.969, agent_2/loss=384.606, agent_3/loss=743.096, agent_4/loss=1482.312, agent_5/loss=0.017, env_step=20000, len=11, n/ep=0, n/st=10, rew=156.50]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #20: test_reward: 203.625000 ± 84.095351, best_reward: 631.000000 ± 21.307276 in #19\n",
      "Final state:\n",
      "[[1 1 1 1 1]\n",
      " [1 1 1 1 1]\n",
      " [1 1 1 0 0]\n",
      " [1 1 0 1 1]\n",
      " [1 1 0 1 1]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #1: 1001it [00:00, 1868.85it/s, agent_1/loss=842.206, agent_2/loss=1146.384, agent_3/loss=735.325, agent_4/loss=857.548, agent_5/loss=0.030, env_step=1000, len=0, n/ep=0, n/st=10, rew=0.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #1: test_reward: -891.550000 ± 192.966830, best_reward: -767.175000 ± 185.245953 in #0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #2: 1001it [00:00, 1870.67it/s, agent_1/loss=949.044, agent_2/loss=982.320, agent_3/loss=707.303, agent_4/loss=700.171, agent_5/loss=0.001, env_step=2000, len=0, n/ep=0, n/st=10, rew=0.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #2: test_reward: -1001.525000 ± 186.700310, best_reward: -767.175000 ± 185.245953 in #0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #3: 1001it [00:00, 1784.02it/s, agent_1/loss=969.651, agent_2/loss=1393.024, agent_3/loss=732.377, agent_4/loss=484.443, agent_5/loss=0.000, env_step=3000, len=6, n/ep=0, n/st=10, rew=171.50]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #3: test_reward: 133.100000 ± 67.284768, best_reward: 133.100000 ± 67.284768 in #3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #4: 1001it [00:00, 1693.09it/s, agent_1/loss=1943.372, agent_2/loss=2342.143, agent_3/loss=1672.086, agent_4/loss=543.858, agent_5/loss=0.005, env_step=4000, len=6, n/ep=2, n/st=10, rew=171.50]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #4: test_reward: 131.600000 ± 66.575446, best_reward: 133.100000 ± 67.284768 in #3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #5: 1001it [00:00, 1663.14it/s, agent_1/loss=823.842, agent_2/loss=1083.985, agent_3/loss=1020.230, agent_4/loss=1301.456, agent_5/loss=0.003, env_step=5000, len=6, n/ep=0, n/st=10, rew=171.50]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #5: test_reward: 131.600000 ± 66.575446, best_reward: 133.100000 ± 67.284768 in #3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #6: 1001it [00:00, 1634.53it/s, agent_1/loss=368.133, agent_2/loss=967.632, agent_3/loss=465.369, agent_4/loss=645.197, agent_5/loss=0.001, env_step=6000, len=6, n/ep=2, n/st=10, rew=146.50]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #6: test_reward: 114.100000 ± 57.593750, best_reward: 133.100000 ± 67.284768 in #3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #7: 1001it [00:00, 1636.74it/s, agent_1/loss=620.184, agent_2/loss=1067.747, agent_3/loss=846.850, agent_4/loss=665.374, agent_5/loss=0.002, env_step=7000, len=26, n/ep=0, n/st=10, rew=543.50]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #7: test_reward: 286.325000 ± 260.135927, best_reward: 286.325000 ± 260.135927 in #7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #8: 1001it [00:00, 1651.65it/s, agent_1/loss=596.312, agent_2/loss=591.860, agent_3/loss=598.157, agent_4/loss=610.985, agent_5/loss=0.002, env_step=8000, len=6, n/ep=0, n/st=10, rew=85.50]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #8: test_reward: 180.825000 ± 128.914218, best_reward: 286.325000 ± 260.135927 in #7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #9: 1001it [00:00, 1623.34it/s, agent_1/loss=495.750, agent_2/loss=704.523, agent_3/loss=271.091, agent_4/loss=328.952, agent_5/loss=0.002, env_step=9000, len=7, n/ep=4, n/st=10, rew=197.56]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #9: test_reward: 160.875000 ± 117.214294, best_reward: 286.325000 ± 260.135927 in #7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #10: 1001it [00:00, 1608.59it/s, agent_1/loss=578.584, agent_2/loss=588.569, agent_3/loss=711.552, agent_4/loss=557.836, agent_5/loss=0.004, env_step=10000, len=6, n/ep=2, n/st=10, rew=146.50]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #10: test_reward: 160.875000 ± 117.214294, best_reward: 286.325000 ± 260.135927 in #7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #11: 1001it [00:00, 1508.66it/s, agent_1/loss=346.639, agent_2/loss=1214.161, agent_3/loss=967.397, agent_4/loss=1389.027, agent_5/loss=0.005, env_step=11000, len=7, n/ep=3, n/st=10, rew=224.33]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #11: test_reward: 207.575000 ± 85.967003, best_reward: 286.325000 ± 260.135927 in #7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #12: 1001it [00:00, 1617.96it/s, agent_1/loss=375.011, agent_2/loss=833.900, agent_3/loss=428.955, agent_4/loss=954.933, agent_5/loss=0.009, env_step=12000, len=6, n/ep=2, n/st=10, rew=146.50]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #12: test_reward: 173.375000 ± 116.344599, best_reward: 286.325000 ± 260.135927 in #7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #13: 1001it [00:00, 1606.90it/s, agent_1/loss=235.690, agent_2/loss=1046.481, agent_3/loss=494.895, agent_4/loss=906.888, agent_5/loss=0.009, env_step=13000, len=8, n/ep=2, n/st=10, rew=72.75]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #13: test_reward: 160.875000 ± 117.214294, best_reward: 286.325000 ± 260.135927 in #7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #14: 1001it [00:00, 1599.27it/s, agent_1/loss=142.551, agent_2/loss=1278.273, agent_3/loss=275.124, agent_4/loss=528.132, agent_5/loss=0.011, env_step=14000, len=6, n/ep=2, n/st=10, rew=73.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #14: test_reward: 160.875000 ± 117.214294, best_reward: 286.325000 ± 260.135927 in #7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #15: 1001it [00:00, 1600.55it/s, agent_1/loss=162.057, agent_2/loss=808.121, agent_3/loss=234.725, agent_4/loss=222.846, agent_5/loss=0.001, env_step=15000, len=6, n/ep=2, n/st=10, rew=146.50]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #15: test_reward: 160.875000 ± 117.214294, best_reward: 286.325000 ± 260.135927 in #7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #16: 1001it [00:00, 1603.38it/s, agent_1/loss=114.455, agent_2/loss=825.619, agent_3/loss=988.369, agent_4/loss=213.189, agent_5/loss=0.001, env_step=16000, len=6, n/ep=1, n/st=10, rew=194.50]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #16: test_reward: 184.875000 ± 116.726992, best_reward: 286.325000 ± 260.135927 in #7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #17: 1001it [00:00, 1605.86it/s, agent_1/loss=90.013, agent_2/loss=1115.640, agent_3/loss=1066.278, agent_4/loss=727.482, agent_5/loss=0.001, env_step=17000, len=6, n/ep=1, n/st=10, rew=-0.50]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #17: test_reward: 160.875000 ± 117.214294, best_reward: 286.325000 ± 260.135927 in #7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #18: 1001it [00:00, 1628.67it/s, agent_1/loss=77.334, agent_2/loss=699.044, agent_3/loss=1024.554, agent_4/loss=542.603, agent_5/loss=0.001, env_step=18000, len=6, n/ep=3, n/st=10, rew=97.50]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #18: test_reward: 160.875000 ± 117.214294, best_reward: 286.325000 ± 260.135927 in #7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #19: 1001it [00:00, 1619.64it/s, agent_1/loss=88.693, agent_2/loss=788.599, agent_3/loss=935.661, agent_4/loss=475.698, agent_5/loss=0.004, env_step=19000, len=6, n/ep=4, n/st=10, rew=146.50]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #19: test_reward: 160.875000 ± 117.214294, best_reward: 286.325000 ± 260.135927 in #7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #20: 1001it [00:00, 1639.04it/s, agent_1/loss=75.447, agent_2/loss=609.052, agent_3/loss=960.476, agent_4/loss=510.122, agent_5/loss=0.003, env_step=20000, len=6, n/ep=0, n/st=10, rew=146.50]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #20: test_reward: 160.875000 ± 117.214294, best_reward: 286.325000 ± 260.135927 in #7\n",
      "Final state:\n",
      "[[1 0 1 1 1]\n",
      " [0 1 0 0 0]\n",
      " [1 0 1 0 0]\n",
      " [1 0 0 1 0]\n",
      " [1 0 0 0 1]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #1: 1001it [00:00, 1871.15it/s, agent_1/loss=722.665, agent_2/loss=1457.602, agent_3/loss=789.564, agent_4/loss=878.738, agent_5/loss=0.029, env_step=1000, len=0, n/ep=0, n/st=10, rew=0.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #1: test_reward: -967.550000 ± 126.853991, best_reward: -820.800000 ± 251.322273 in #0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #2: 1001it [00:00, 1686.31it/s, agent_1/loss=1028.803, agent_2/loss=886.809, agent_3/loss=520.811, agent_4/loss=605.537, agent_5/loss=0.001, env_step=2000, len=0, n/ep=0, n/st=10, rew=0.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #2: test_reward: -866.225000 ± 128.432056, best_reward: -820.800000 ± 251.322273 in #0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #3: 1001it [00:00, 1795.66it/s, agent_1/loss=991.272, agent_2/loss=1158.147, agent_3/loss=744.059, agent_4/loss=1590.111, agent_5/loss=0.001, env_step=3000, len=11, n/ep=0, n/st=10, rew=156.50]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #3: test_reward: 57.225000 ± 377.765113, best_reward: 57.225000 ± 377.765113 in #3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #4: 1001it [00:00, 1577.08it/s, agent_1/loss=1494.348, agent_2/loss=1395.527, agent_3/loss=1481.151, agent_4/loss=3860.596, agent_5/loss=0.004, env_step=4000, len=6, n/ep=0, n/st=10, rew=171.50]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #4: test_reward: 169.000000 ± 7.500000, best_reward: 169.000000 ± 7.500000 in #4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #5: 1001it [00:00, 1715.10it/s, agent_1/loss=880.220, agent_2/loss=756.632, agent_3/loss=1644.059, agent_4/loss=1434.432, agent_5/loss=0.001, env_step=5000, len=6, n/ep=3, n/st=10, rew=171.50]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #5: test_reward: 169.000000 ± 7.500000, best_reward: 169.000000 ± 7.500000 in #4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #6: 1001it [00:00, 1723.50it/s, agent_1/loss=285.578, agent_2/loss=455.992, agent_3/loss=1700.692, agent_4/loss=998.205, agent_5/loss=0.000, env_step=6000, len=6, n/ep=0, n/st=10, rew=171.50]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #6: test_reward: 169.000000 ± 7.500000, best_reward: 169.000000 ± 7.500000 in #4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #7: 1001it [00:00, 1720.27it/s, agent_1/loss=522.166, agent_2/loss=710.566, agent_3/loss=1523.373, agent_4/loss=861.324, agent_5/loss=0.002, env_step=7000, len=6, n/ep=0, n/st=10, rew=171.50]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #7: test_reward: 169.000000 ± 7.500000, best_reward: 169.000000 ± 7.500000 in #4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #8: 1001it [00:00, 1722.86it/s, agent_1/loss=130.389, agent_2/loss=379.760, agent_3/loss=975.032, agent_4/loss=319.189, agent_5/loss=0.004, env_step=8000, len=6, n/ep=3, n/st=10, rew=171.50]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #8: test_reward: 169.000000 ± 7.500000, best_reward: 169.000000 ± 7.500000 in #4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #9: 1001it [00:00, 1722.79it/s, agent_1/loss=356.488, agent_2/loss=235.326, agent_3/loss=1256.999, agent_4/loss=389.541, agent_5/loss=0.002, env_step=9000, len=6, n/ep=0, n/st=10, rew=171.50]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #9: test_reward: 169.000000 ± 7.500000, best_reward: 169.000000 ± 7.500000 in #4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #10: 1001it [00:00, 1677.68it/s, agent_1/loss=321.587, agent_2/loss=370.805, agent_3/loss=1057.571, agent_4/loss=523.060, agent_5/loss=0.002, env_step=10000, len=6, n/ep=0, n/st=10, rew=166.50]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #10: test_reward: 169.000000 ± 7.500000, best_reward: 169.000000 ± 7.500000 in #4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #11: 1001it [00:00, 1678.57it/s, agent_1/loss=344.141, agent_2/loss=391.149, agent_3/loss=1121.137, agent_4/loss=293.280, agent_5/loss=0.000, env_step=11000, len=6, n/ep=4, n/st=10, rew=171.50]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #11: test_reward: 188.100000 ± 49.800000, best_reward: 188.100000 ± 49.800000 in #11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #12: 1001it [00:00, 1652.59it/s, agent_1/loss=124.515, agent_2/loss=259.393, agent_3/loss=1350.346, agent_4/loss=194.298, agent_5/loss=0.000, env_step=12000, len=6, n/ep=1, n/st=10, rew=171.50]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #12: test_reward: 169.000000 ± 7.500000, best_reward: 188.100000 ± 49.800000 in #11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #13: 1001it [00:00, 1650.47it/s, agent_1/loss=148.018, agent_2/loss=285.120, agent_3/loss=1404.106, agent_4/loss=182.748, agent_5/loss=0.001, env_step=13000, len=6, n/ep=0, n/st=10, rew=171.50]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #13: test_reward: 169.000000 ± 7.500000, best_reward: 188.100000 ± 49.800000 in #11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #14: 1001it [00:00, 1506.80it/s, agent_1/loss=19.558, agent_2/loss=154.408, agent_3/loss=1422.778, agent_4/loss=329.818, agent_5/loss=0.001, env_step=14000, len=6, n/ep=1, n/st=10, rew=171.50]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #14: test_reward: 169.000000 ± 7.500000, best_reward: 188.100000 ± 49.800000 in #11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #15: 1001it [00:00, 1658.56it/s, agent_1/loss=41.075, agent_2/loss=414.858, agent_3/loss=1363.579, agent_4/loss=435.042, agent_5/loss=0.001, env_step=15000, len=6, n/ep=1, n/st=10, rew=171.50]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #15: test_reward: 169.000000 ± 7.500000, best_reward: 188.100000 ± 49.800000 in #11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #16: 1001it [00:00, 1659.99it/s, agent_1/loss=8.175, agent_2/loss=403.061, agent_3/loss=1334.166, agent_4/loss=263.329, agent_5/loss=0.001, env_step=16000, len=6, n/ep=0, n/st=10, rew=171.50]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #16: test_reward: 169.000000 ± 7.500000, best_reward: 188.100000 ± 49.800000 in #11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #17: 1001it [00:00, 1677.24it/s, agent_1/loss=1.288, agent_2/loss=266.161, agent_3/loss=1355.284, agent_4/loss=254.473, agent_5/loss=0.001, env_step=17000, len=6, n/ep=0, n/st=10, rew=171.50]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #17: test_reward: 169.000000 ± 7.500000, best_reward: 188.100000 ± 49.800000 in #11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #18: 1001it [00:00, 1687.80it/s, agent_1/loss=1.118, agent_2/loss=244.711, agent_3/loss=1279.270, agent_4/loss=190.922, agent_5/loss=0.001, env_step=18000, len=6, n/ep=3, n/st=10, rew=146.50]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #18: test_reward: 146.500000 ± 0.000000, best_reward: 188.100000 ± 49.800000 in #11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #19: 1001it [00:00, 1690.56it/s, agent_1/loss=5.007, agent_2/loss=141.229, agent_3/loss=1115.946, agent_4/loss=129.037, agent_5/loss=0.000, env_step=19000, len=6, n/ep=0, n/st=10, rew=146.50]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #19: test_reward: 146.500000 ± 0.000000, best_reward: 188.100000 ± 49.800000 in #11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #20: 1001it [00:00, 1682.48it/s, agent_1/loss=6.296, agent_2/loss=136.615, agent_3/loss=868.123, agent_4/loss=112.378, agent_5/loss=0.000, env_step=20000, len=6, n/ep=0, n/st=10, rew=146.50]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #20: test_reward: 146.500000 ± 0.000000, best_reward: 188.100000 ± 49.800000 in #11\n",
      "Final state:\n",
      "[[1 0 0 1 1]\n",
      " [0 1 1 1 1]\n",
      " [0 1 1 0 0]\n",
      " [1 1 0 1 0]\n",
      " [1 1 0 0 1]]\n"
     ]
    }
   ],
   "source": [
    "metrics = []\n",
    "actions = []\n",
    "\n",
    "## TEST COALITION WEIGHTS\n",
    "# data = pd.read_csv('data/coalition_weights.csv', header=None).values\n",
    "# direct = np.arange(0,1.1,0.1)\n",
    "# weight_name = \"Coalition weight\"\n",
    "\n",
    "# for i in direct:\n",
    "#     weights = {'direct': i, 'indirect':i}\n",
    "\n",
    "## TEST POWER WEIGHTS\n",
    "# data = pd.read_csv('data/power_weights.csv', header=None).values\n",
    "\n",
    "# w_power = np.arange(1,11,1)\n",
    "# cur_weights = w_power\n",
    "# weight_name = \"Power weight\"\n",
    "\n",
    "# for i in w_power:\n",
    "#     weights = {\"w_power\":i}\n",
    "\n",
    "## TEST POSITION WEIGHTS\n",
    "# data = pd.read_csv('data/position_weights.csv', header=None).values\n",
    "\n",
    "# w_position = np.arange(0,5.5,0.5)\n",
    "# cur_weights = w_position\n",
    "# weight_name = \"Position weights\"\n",
    "\n",
    "# for i in w_position:\n",
    "#     weights = {\"w_position\":i}\n",
    "\n",
    "## TEST DISTANCE WEIGHTS\n",
    "# data = pd.read_csv('data/distance_weights.csv', header=None).values\n",
    "\n",
    "# w_distance = np.arange(0,35,5)\n",
    "# cur_weights = w_distance\n",
    "# weight_name = \"Distance weights\"\n",
    "\n",
    "# for i in w_distance:\n",
    "#     weights = {\"w_distance\":i}\n",
    "\n",
    "\n",
    "## TEST PROB SUCCESS ALONE\n",
    "data = pd.read_csv('data/prob_success_alone_weight.csv', header=None).values\n",
    "\n",
    "prob_success_alone = np.arange(0,1.1,0.1)\n",
    "cur_weights = prob_success_alone\n",
    "weight_name = \"Probability stakeholder with power, urgency, and legitimacy succeeds alone\"\n",
    "\n",
    "for i in prob_success_alone:\n",
    "    weights = {\"prob_success_alone\":i}\n",
    "####\n",
    "\n",
    "    args = get_args()\n",
    "    result, policies = train_agent(args, stakeholder_vals=data, weights=weights)\n",
    "\n",
    "    env = get_env(data)\n",
    "    obs, info = env.reset()\n",
    "    done = False\n",
    "    while not done:\n",
    "        agent = env.env.agent_selection\n",
    "        policy = policies[agent]\n",
    "        action = policy.forward(batch=Batch(obs=[obs], info=[info])).act[0]\n",
    "    \n",
    "        recipient = f'agent_{action + 1}'\n",
    "        # print(f'{agent} targeting {recipient}')\n",
    "        # print(f'Actions: {env.env.agent_actions[agent]}')\n",
    "        # print(env.env.observe(None))\n",
    "        # print()\n",
    "        \n",
    "        obs, rew, done, truncated, info = env.step(action)\n",
    "    metrics.append(env.env.infos['agent_1'])\n",
    "    actions.append(env.env.agent_actions['agent_1'])\n",
    "    print('Final state:')\n",
    "    print(env.env.observe(None))\n",
    "    env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get metrics\n",
    "primary_steps = [item['metrics'][0] for item in metrics]\n",
    "final_prob = [item['metrics'][1] for item in metrics]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5, 5, 2, 4, 6, 4, 6, 5, 6, 4, 6]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "primary_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1, 0.5148, 0.7794, 1, 0.849, 1, 1, 1, 0.9462, 0.7939]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# final probabilities \n",
    "[round(val, 4) for val in final_prob]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'actions': [3, 3, 1, 1, 4]},\n",
       " {'actions': [1, 1, 3, 3, 4]},\n",
       " {'actions': [4, 4]},\n",
       " {'actions': [3, 3, 4, 4]},\n",
       " {'actions': [3, 3, 1, 1, 1, 4]},\n",
       " {'actions': [3, 3, 4, 4]},\n",
       " {'actions': [3, 3, 1, 3, 3, 4]},\n",
       " {'actions': [3, 3, 1, 1, 4]},\n",
       " {'actions': [3, 3, 3, 3, 1, 4]},\n",
       " {'actions': [3, 3, 3, 4]},\n",
       " {'actions': [3, 3, 3, 3, 4, 4]}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# primary actions\n",
    "actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.75       -0.75       -0.         -0.64147829 -1.         -0.58891346\n",
      " -1.         -0.75       -1.         -0.52840383 -1.25966558]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# normalize and plot\n",
    "def minmax(lst):\n",
    "    return (lst - np.min(lst)) / (np.max(lst) - np.min(lst))\n",
    "\n",
    "normalized_steps = minmax(primary_steps)\n",
    "eval_metric = -(normalized_steps / final_prob)\n",
    "\n",
    "print(\"METRIC:\",eval_metric)\n",
    "\n",
    "def plot_metric(weights, eval_metric, weight_name):\n",
    "    plt.plot(weights, eval_metric)\n",
    "    plt.title(f\"Optimal policy: {weight_name}\")\n",
    "    plt.xlabel(\"Weight\")\n",
    "    plt.ylabel(\"Evaluation metric\")\n",
    "    plt.show()\n",
    "\n",
    "plot_metric(cur_weights, eval_metric, weight_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "agent_1 targeting agent_4\n",
      "Actions: {'actions': []}\n",
      "[[1 0 0 0 0]\n",
      " [0 1 0 0 0]\n",
      " [0 0 1 0 0]\n",
      " [0 0 0 1 0]\n",
      " [0 0 0 0 1]]\n",
      "\n",
      "agent_2 targeting agent_3\n",
      "Actions: {'actions': []}\n",
      "[[1 0 0 0 0]\n",
      " [0 1 0 0 0]\n",
      " [0 0 1 0 0]\n",
      " [0 0 0 1 0]\n",
      " [0 0 0 0 1]]\n",
      "\n",
      "agent_3 targeting agent_2\n",
      "Actions: {'actions': []}\n",
      "[[1 0 0 0 0]\n",
      " [0 1 0 0 0]\n",
      " [0 0 1 0 0]\n",
      " [0 0 0 1 0]\n",
      " [0 0 0 0 1]]\n",
      "\n",
      "agent_4 targeting agent_2\n",
      "Actions: {'actions': []}\n",
      "[[1 0 0 0 0]\n",
      " [0 1 0 0 0]\n",
      " [0 0 1 0 0]\n",
      " [0 0 0 1 0]\n",
      " [0 0 0 0 1]]\n",
      "\n",
      "agent_5 targeting agent_4\n",
      "Actions: {'actions': []}\n",
      "[[1 0 0 0 0]\n",
      " [0 1 0 0 0]\n",
      " [0 0 1 0 0]\n",
      " [0 0 0 1 0]\n",
      " [0 0 0 0 1]]\n",
      "\n",
      "agent_1 targeting agent_4\n",
      "Actions: {'actions': [3]}\n",
      "[[1 0 0 0 0]\n",
      " [0 1 0 0 0]\n",
      " [0 0 1 0 0]\n",
      " [0 0 0 1 0]\n",
      " [0 0 0 0 1]]\n",
      "\n",
      "agent_2 targeting agent_3\n",
      "Actions: {'actions': [2]}\n",
      "[[1 0 0 1 0]\n",
      " [0 1 0 0 0]\n",
      " [0 0 1 0 0]\n",
      " [1 0 0 1 0]\n",
      " [0 0 0 0 1]]\n",
      "\n",
      "agent_3 targeting agent_2\n",
      "Actions: {'actions': [1]}\n",
      "[[1 0 0 1 0]\n",
      " [0 1 0 0 0]\n",
      " [0 0 1 0 0]\n",
      " [1 0 0 1 0]\n",
      " [0 0 0 0 1]]\n",
      "\n",
      "agent_4 targeting agent_2\n",
      "Actions: {'actions': [1]}\n",
      "[[1 0 0 1 0]\n",
      " [0 1 0 0 0]\n",
      " [0 0 1 0 0]\n",
      " [1 0 0 1 0]\n",
      " [0 0 0 0 1]]\n",
      "\n",
      "agent_5 targeting agent_4\n",
      "Actions: {'actions': [3]}\n",
      "[[1 0 0 1 0]\n",
      " [0 1 0 0 0]\n",
      " [0 0 1 0 0]\n",
      " [1 0 0 1 0]\n",
      " [0 0 0 0 1]]\n",
      "\n",
      "agent_1 targeting agent_4\n",
      "Actions: {'actions': [3, 3]}\n",
      "[[1 0 0 1 0]\n",
      " [0 1 0 0 0]\n",
      " [0 0 1 0 0]\n",
      " [1 0 0 1 0]\n",
      " [0 0 0 0 1]]\n",
      "\n",
      "agent_2 targeting agent_3\n",
      "Actions: {'actions': [2, 2]}\n",
      "[[1 0 0 1 0]\n",
      " [0 1 0 0 0]\n",
      " [0 0 1 0 0]\n",
      " [1 0 0 1 0]\n",
      " [0 0 0 0 1]]\n",
      "\n",
      "agent_3 targeting agent_2\n",
      "Actions: {'actions': [1, 1]}\n",
      "[[1 0 0 1 0]\n",
      " [0 1 0 0 0]\n",
      " [0 0 1 0 0]\n",
      " [1 0 0 1 0]\n",
      " [0 0 0 0 1]]\n",
      "\n",
      "agent_4 targeting agent_2\n",
      "Actions: {'actions': [1, 1]}\n",
      "[[1 0 0 1 0]\n",
      " [0 1 1 0 0]\n",
      " [0 1 1 0 0]\n",
      " [1 0 0 1 0]\n",
      " [0 0 0 0 1]]\n",
      "\n",
      "agent_5 targeting agent_4\n",
      "Actions: {'actions': [3, 3]}\n",
      "[[1 0 0 1 0]\n",
      " [0 1 1 0 0]\n",
      " [0 1 1 0 0]\n",
      " [1 0 0 1 0]\n",
      " [0 0 0 0 1]]\n",
      "\n",
      "agent_1 targeting agent_4\n",
      "Actions: {'actions': [3, 3, 3]}\n",
      "[[1 0 0 1 0]\n",
      " [0 1 1 0 0]\n",
      " [0 1 1 0 0]\n",
      " [1 0 0 1 0]\n",
      " [0 0 0 0 1]]\n",
      "\n",
      "agent_2 targeting agent_5\n",
      "Actions: {'actions': [2, 2, 2]}\n",
      "[[1 0 0 1 0]\n",
      " [0 1 1 0 0]\n",
      " [0 1 1 0 0]\n",
      " [1 0 0 1 0]\n",
      " [0 0 0 0 1]]\n",
      "\n",
      "agent_3 targeting agent_2\n",
      "Actions: {'actions': [1, 1, 1]}\n",
      "[[1 0 0 1 0]\n",
      " [0 1 1 0 1]\n",
      " [0 1 1 0 0]\n",
      " [1 0 0 1 0]\n",
      " [0 1 0 0 1]]\n",
      "\n",
      "agent_4 targeting agent_2\n",
      "Actions: {'actions': [1, 1, 1]}\n",
      "[[1 0 0 1 0]\n",
      " [0 1 1 0 1]\n",
      " [0 1 1 0 0]\n",
      " [1 0 0 1 0]\n",
      " [0 1 0 0 1]]\n",
      "\n",
      "agent_5 targeting agent_4\n",
      "Actions: {'actions': [3, 3, 3]}\n",
      "[[1 0 0 1 0]\n",
      " [0 1 1 1 1]\n",
      " [0 1 1 0 0]\n",
      " [1 1 0 1 0]\n",
      " [0 1 0 0 1]]\n",
      "\n",
      "agent_1 targeting agent_5\n",
      "Actions: {'actions': [3, 3, 3, 3]}\n",
      "[[1 0 0 1 0]\n",
      " [0 1 1 1 1]\n",
      " [0 1 1 0 0]\n",
      " [1 1 0 1 0]\n",
      " [0 1 0 0 1]]\n",
      "\n",
      "agent_2 targeting agent_4\n",
      "Actions: {'actions': [2, 2, 2, 4]}\n",
      "[[1 0 0 1 0]\n",
      " [0 1 1 1 1]\n",
      " [0 1 1 0 0]\n",
      " [1 1 0 1 0]\n",
      " [0 1 0 0 1]]\n",
      "\n",
      "agent_3 targeting agent_2\n",
      "Actions: {'actions': [1, 1, 1, 1]}\n",
      "[[1 0 0 1 0]\n",
      " [0 1 1 1 1]\n",
      " [0 1 1 0 0]\n",
      " [1 1 0 1 0]\n",
      " [0 1 0 0 1]]\n",
      "\n",
      "agent_4 targeting agent_2\n",
      "Actions: {'actions': [1, 1, 1, 1]}\n",
      "[[1 0 0 1 0]\n",
      " [0 1 1 1 1]\n",
      " [0 1 1 0 0]\n",
      " [1 1 0 1 0]\n",
      " [0 1 0 0 1]]\n",
      "\n",
      "agent_5 targeting agent_4\n",
      "Actions: {'actions': [3, 3, 3, 3]}\n",
      "[[1 0 0 1 0]\n",
      " [0 1 1 1 1]\n",
      " [0 1 1 0 0]\n",
      " [1 1 0 1 0]\n",
      " [0 1 0 0 1]]\n",
      "\n",
      "agent_1 targeting agent_5\n",
      "Actions: {'actions': [3, 3, 3, 3, 4]}\n",
      "[[1 0 0 1 0]\n",
      " [0 1 1 1 1]\n",
      " [0 1 1 0 0]\n",
      " [1 1 0 1 0]\n",
      " [0 1 0 0 1]]\n",
      "\n",
      "Final state:\n",
      "[[1 0 0 1 1]\n",
      " [0 1 1 1 1]\n",
      " [0 1 1 0 0]\n",
      " [1 1 0 1 0]\n",
      " [1 1 0 0 1]]\n"
     ]
    }
   ],
   "source": [
    "env = get_env(data)\n",
    "obs, info = env.reset()\n",
    "done = False\n",
    "while not done:\n",
    "    agent = env.env.agent_selection\n",
    "    policy = policies[agent]\n",
    "    action = policy.forward(batch=Batch(obs=[obs], info=[info])).act[0]\n",
    "\n",
    "    recipient = f'agent_{action + 1}'\n",
    "    print(f'{agent} targeting {recipient}')\n",
    "    print(f'Actions: {env.env.agent_actions[agent]}')\n",
    "    print(env.env.observe(None))\n",
    "    print()\n",
    "    \n",
    "    obs, rew, done, truncated, info = env.step(action)\n",
    "print('Final state:')\n",
    "print(env.env.observe(None))\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'metrics': [6, 0.7938614960486916]}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.env.infos['agent_1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'actions': [3, 3, 3, 3, 4, 4]}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.env.agent_actions['agent_1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
